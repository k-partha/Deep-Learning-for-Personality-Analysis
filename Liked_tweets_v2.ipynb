{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Liked_tweets_v2.ipynb","provenance":[{"file_id":"1FPJkL9fXwdqXIC4sv3vquwOu72PmpKVs","timestamp":1621546077716}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"406e1951535744418ebd0c8d920eb35d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6c95393dd2194b57a1b0db7dfae293f3","IPY_MODEL_b681080658ba4f21902ad86602a778dd"],"layout":"IPY_MODEL_16e03c50e6ab4d24b73146bb1df8210d"}},"6c95393dd2194b57a1b0db7dfae293f3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"Downloading: 100%","description_tooltip":null,"layout":"IPY_MODEL_82dcb7d9586b4e4e9c64b1bdce94424e","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_92c102a78ef5466394ea9ba68f2c1805","value":231508}},"b681080658ba4f21902ad86602a778dd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_be7391940c754dc3a7957d2b960ad0e2","placeholder":"​","style":"IPY_MODEL_b103013777b3486c8ea0365ad830b90f","value":" 232k/232k [00:02&lt;00:00, 99.7kB/s]"}},"16e03c50e6ab4d24b73146bb1df8210d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"82dcb7d9586b4e4e9c64b1bdce94424e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"92c102a78ef5466394ea9ba68f2c1805":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"be7391940c754dc3a7957d2b960ad0e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b103013777b3486c8ea0365ad830b90f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1ed0da8fbdd242389131039e01a54a1b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3c837d15c06c4e2fa489e4cbd32a4f6f","IPY_MODEL_607e3f9eb38240b0ba46fb621342f0cd"],"layout":"IPY_MODEL_c1e364f15ec74b83b56b981d4a9da869"}},"3c837d15c06c4e2fa489e4cbd32a4f6f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"Downloading: 100%","description_tooltip":null,"layout":"IPY_MODEL_ccfe190c96774a16a97dab15c053adca","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_57f2de64e2ec41d2a20afb18a5c619c6","value":28}},"607e3f9eb38240b0ba46fb621342f0cd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_11895b23c5a04ac6947ab6e234e22f37","placeholder":"​","style":"IPY_MODEL_dacf18af80634c6ab2d2974b15935ad4","value":" 28.0/28.0 [00:02&lt;00:00, 13.6B/s]"}},"c1e364f15ec74b83b56b981d4a9da869":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ccfe190c96774a16a97dab15c053adca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"57f2de64e2ec41d2a20afb18a5c619c6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"11895b23c5a04ac6947ab6e234e22f37":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dacf18af80634c6ab2d2974b15935ad4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d43ffdd2c54f41df9afd92cb237186fa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4b93e295c0454d19a6ff1c24c049a1a1","IPY_MODEL_0b01146831084ac29ab5e5183aa9b5c2"],"layout":"IPY_MODEL_31a972de30ae49c89e470e84dd89ed40"}},"4b93e295c0454d19a6ff1c24c049a1a1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"Downloading: 100%","description_tooltip":null,"layout":"IPY_MODEL_bfd38dcc4148475d976c52684c8a6c2b","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b6440b2ee582462faf1b1327aa268a14","value":466062}},"0b01146831084ac29ab5e5183aa9b5c2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_88edfa01496340ee904bd8da0fe20368","placeholder":"​","style":"IPY_MODEL_74dfebdb7bb14dd2b66c0ea877008ec5","value":" 466k/466k [00:00&lt;00:00, 510kB/s]"}},"31a972de30ae49c89e470e84dd89ed40":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bfd38dcc4148475d976c52684c8a6c2b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b6440b2ee582462faf1b1327aa268a14":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"88edfa01496340ee904bd8da0fe20368":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"74dfebdb7bb14dd2b66c0ea877008ec5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d7eae61dd9f14fbd8e39fda7cab4789a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4bacd2b6e2cc41669e467db2c602923a","IPY_MODEL_90b7fbbbc1ec493f9047c9fefa15967d"],"layout":"IPY_MODEL_eedca87254e7467ba25c7e40fe0fc937"}},"4bacd2b6e2cc41669e467db2c602923a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"Downloading: 100%","description_tooltip":null,"layout":"IPY_MODEL_de04b2e7d2a6482cba071549562c163d","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8d33917f76874e309d742e770a1f1d42","value":570}},"90b7fbbbc1ec493f9047c9fefa15967d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d5b98fe261624c07b6931d539fe9ce48","placeholder":"​","style":"IPY_MODEL_23370a5038594115bbe884f43f5908cb","value":" 570/570 [00:00&lt;00:00, 595B/s]"}},"eedca87254e7467ba25c7e40fe0fc937":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"de04b2e7d2a6482cba071549562c163d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d33917f76874e309d742e770a1f1d42":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"d5b98fe261624c07b6931d539fe9ce48":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"23370a5038594115bbe884f43f5908cb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bd1285f3bf404c3583e36a0531a1b31f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5511c9002a7f46b198ef99f94076ae57","IPY_MODEL_a9a733a935f34c16ad6c4a6ffaf13186"],"layout":"IPY_MODEL_f131849b13234badbfcc0db6b059e867"}},"5511c9002a7f46b198ef99f94076ae57":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"Downloading: 100%","description_tooltip":null,"layout":"IPY_MODEL_98bf3f867d234a18b06a4826d2bed4c5","max":440473133,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4eadc0c7dba14659b05e8867c532d684","value":440473133}},"a9a733a935f34c16ad6c4a6ffaf13186":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_54afe0258abc49a1ac79c1e7f2b03ef8","placeholder":"​","style":"IPY_MODEL_fec95d1f178a4feb8870f027dd4600e8","value":" 440M/440M [00:07&lt;00:00, 60.2MB/s]"}},"f131849b13234badbfcc0db6b059e867":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"98bf3f867d234a18b06a4826d2bed4c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4eadc0c7dba14659b05e8867c532d684":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"54afe0258abc49a1ac79c1e7f2b03ef8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fec95d1f178a4feb8870f027dd4600e8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"9nFkME77f1Zh"},"source":["# Fitting BERT Classifier to Twitter MBTI"]},{"cell_type":"code","metadata":{"id":"eTCP80HqWCZs"},"source":["import tensorflow as tf\n","import torch\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from sklearn.model_selection import train_test_split\n","from transformers import BertTokenizer, BertConfig\n","from transformers import AdamW, BertForSequenceClassification\n","from tqdm import tqdm, trange\n","import pandas as pd\n","import io\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import roc_curve"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6DkVY2HIWRPC","outputId":"4f24f89c-977f-475c-8a4c-0dce3cf85715"},"source":["# If there's a GPU available...\n","if torch.cuda.is_available():    \n","\n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["There are 4 GPU(s) available.\n","We will use the GPU: TITAN X (Pascal)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pE09O3gHpIN_"},"source":["def expand_frame(df, length):\n","    ndf = pd.DataFrame()\n","\n","    for i in range(1,30):\n","        adf = df.copy(deep= True)\n","        adf['text'] = adf['text'].apply(lambda x: x[0 + length*5*i : length * 5 * (i+1)])\n","        ndf = ndf.append(adf)\n","        ndf.reset_index(drop=True, inplace= True)\n","    return ndf\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VPbf8Yvyf-Hn"},"source":["# Loading the Twitter personality dataset:\n","\n","# OPTION 1 : Load raw without tokenized:"]},{"cell_type":"code","metadata":{"id":"mt2B4sVCsZx7"},"source":["ofile = open('Data/personality_likes_large.csv', encoding = 'cp1252', mode='r' )\n","raw_df = pd.read_csv(ofile ,index_col=0)\n","ofile.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tUSfRNXlpIOB","outputId":"d6c98369-2092-446a-d60f-1299ff9cdb77"},"source":["wifile = open('train_tokenized_large_exp.csv', mode = 'w+')\n","wtfile = open('test_tokenized_large_exp.csv', mode = 'w+')\n","\n","wifile.truncate(0)\n","wtfile.truncate(0)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{"tags":[]},"execution_count":160}]},{"cell_type":"code","metadata":{"id":"UuT2GAh_pIOC"},"source":["train_df, test_df = train_test_split(raw_df, stratify = raw_df['type'], random_state= 1729, test_size= 0.12)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3fTaEC_lpIOD"},"source":["train_df = expand_frame(train_df, 256)\n","\n","train_df.dropna(inplace = True)\n","test_df.to_csv(wtfile)\n","\n","wtfile.close()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yYvVa54NpIOD","outputId":"8b87e877-3a18-442a-d779-8dd1bcfee3ec"},"source":["# Create sentence and label lists\n","sentences = train_df.text.values\n","\n","# We need to add special tokens at the beginning and end of each sentence for BERT to work properly\n","sentences = [\"[CLS] \" + str(sentence) + \" [SEP]\" for sentence in sentences]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'[CLS] 7 @brad_polumbo @mattyglesias Not just can but can\\'t create money out of anything else@MyPillowUSA what’s good?@leftwinggal Nobody is marginalizing Dutch-Americans what the fuckhttps://t.co/OQTASiMt5u@AndrewYang https://t.co/HfvynOpeHu@AndrewYang https://t.co/suSZXLoK2QSo basically, only rich while men can try to make a $, the rest of you are not worthy. OK.  https://t.co/CrQ6q9i40YWho’s this Fucking Guy... $GME $AMC to the  MOON  https://t.co/KUmZPWdO9l@reddittrading I have a romantic relationship with my $AMC stock.Baptist leaders: \"Only men can be in leadership positions, so they can use their strength to protect women.\"\\n\\nAlso Baptist leaders: \"I\\'m sorry, I can\\'t do anything substantial to help sexual abuse victims because other men might say mean things about me.\"\\n\\nA plague of cowards.Democratic leadership laying down the gauntlet on Marjorie Taylor Greene: Steny Hoyer is expected to tell Kevin McCarthy he has 72 hours to strip Marjorie Taylor Greene of her committee assignments or Democrats will bring the issue to the House floor, a source familiar tells me.Stop saying history will judge them.\\n\\nJudge them now.  With judges.Im #notbuyingsilver. Fake news.\\n\\n#GMEtothemoon #gme #GMEGANGSilver is a distraction. Full stopThe United States is still in the middle [SEP]'"]},"metadata":{"tags":[]},"execution_count":164}]},{"cell_type":"code","metadata":{"id":"GigQY7cvpIOE","outputId":"c7c00836-5927-4fa3-a891-5282703d9dec"},"source":["tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n","tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n","\n","train_df['tokenized_texts'] = tokenized_texts"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Tokenize the first sentence:\n","['[CLS]', '@', 'mig', '##non', '##10', '##44', '@', 'mig', '##non', '##10', '##44', '!', '!', '@', 'mig', '##non', '##10', '##44', '@', 'mig', '##non', '##10', '##44', '?', '@', 'mig', '##non', '##10', '##44', '@', 'mig', '##non', '##10', '##44', '.', '.', '.', '.', '@', 'mig', '##non', '##10', '##44', '@', 'mig', '##non', '##10', '##44', '~', '~', '~', '@', 'mig', '##non', '##10', '##44', '.', '.', '[SEP]']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"l3dVNKwQpIOE"},"source":["train_df.to_csv(wifile)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WvYFhrFfpIOE","outputId":"a6e8289d-38c9-4818-9177-5d089bd7cd5d"},"source":["wifile.close()\n","ofile = open('train_tokenized_large_exp.csv',  mode='r' )\n","edf = pd.read_csv(ofile, index_col = 0)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>liked_by</th>\n","      <th>text</th>\n","      <th>type</th>\n","      <th>extravert</th>\n","      <th>intuitive</th>\n","      <th>thinking</th>\n","      <th>judging</th>\n","      <th>NT</th>\n","      <th>SF</th>\n","      <th>NF</th>\n","      <th>ST</th>\n","      <th>NJ</th>\n","      <th>NP</th>\n","      <th>SJ</th>\n","      <th>SP</th>\n","      <th>tokenized_texts</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1281267858639486976</td>\n","      <td>@mignon1044  @mignon1044 !!@mignon1044 @migno...</td>\n","      <td>ISTJ</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>['[CLS]', '@', 'mig', '##non', '##10', '##44',...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>17724827</td>\n","      <td>an sebegitu menyebabkan anda cuba mengganggu d...</td>\n","      <td>INFJ</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>['[CLS]', 'an', 'se', '##be', '##git', '##u', ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>84772941</td>\n","      <td>that I can use strong language.the news: stay...</td>\n","      <td>ENFP</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>['[CLS]', 'that', 'i', 'can', 'use', 'strong',...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3416461845</td>\n","      <td>s://t.co/JZXYOUsCqoSelena Gomez's Makeup Artis...</td>\n","      <td>ESFP</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>['[CLS]', 's', ':', '/', '/', 't', '.', 'co', ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>3075434919</td>\n","      <td>de papai, queria eu ser, único erro dele foi r...</td>\n","      <td>ESFP</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>['[CLS]', 'de', 'papa', '##i', ',', 'que', '##...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>106802</th>\n","      <td>2356621515</td>\n","      <td>NaN</td>\n","      <td>ESFP</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>['[CLS]', '[SEP]']</td>\n","    </tr>\n","    <tr>\n","      <th>106803</th>\n","      <td>706889633670557697</td>\n","      <td>NaN</td>\n","      <td>INFJ</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>['[CLS]', '[SEP]']</td>\n","    </tr>\n","    <tr>\n","      <th>106804</th>\n","      <td>91546751</td>\n","      <td>@LiviaBellona @TheKimClub @PharmDame @PeterFMa...</td>\n","      <td>ENFJ</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>['[CLS]', '@', 'liv', '##ia', '##bell', '##ona...</td>\n","    </tr>\n","    <tr>\n","      <th>106805</th>\n","      <td>24946566</td>\n","      <td>questioned my non-linear liberal arts path. ht...</td>\n","      <td>INTJ</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>['[CLS]', 'questioned', 'my', 'non', '-', 'lin...</td>\n","    </tr>\n","    <tr>\n","      <th>106806</th>\n","      <td>218585083</td>\n","      <td>something about it. No one else can do it for ...</td>\n","      <td>INTJ</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>['[CLS]', 'something', 'about', 'it', '.', 'no...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>106807 rows × 16 columns</p>\n","</div>"],"text/plain":["                   liked_by  \\\n","0       1281267858639486976   \n","1                  17724827   \n","2                  84772941   \n","3                3416461845   \n","4                3075434919   \n","...                     ...   \n","106802           2356621515   \n","106803   706889633670557697   \n","106804             91546751   \n","106805             24946566   \n","106806            218585083   \n","\n","                                                     text  type  extravert  \\\n","0        @mignon1044  @mignon1044 !!@mignon1044 @migno...  ISTJ          0   \n","1       an sebegitu menyebabkan anda cuba mengganggu d...  INFJ          0   \n","2        that I can use strong language.the news: stay...  ENFP          1   \n","3       s://t.co/JZXYOUsCqoSelena Gomez's Makeup Artis...  ESFP          1   \n","4       de papai, queria eu ser, único erro dele foi r...  ESFP          1   \n","...                                                   ...   ...        ...   \n","106802                                                NaN  ESFP          1   \n","106803                                                NaN  INFJ          0   \n","106804  @LiviaBellona @TheKimClub @PharmDame @PeterFMa...  ENFJ          1   \n","106805  questioned my non-linear liberal arts path. ht...  INTJ          0   \n","106806  something about it. No one else can do it for ...  INTJ          0   \n","\n","        intuitive  thinking  judging  NT  SF  NF  ST  NJ  NP  SJ  SP  \\\n","0               0         1        1   0   0   0   1   0   0   1   0   \n","1               1         0        1   0   0   1   0   1   0   0   0   \n","2               1         0        0   0   0   1   0   0   1   0   0   \n","3               0         0        0   0   1   0   0   0   0   0   1   \n","4               0         0        0   0   1   0   0   0   0   0   1   \n","...           ...       ...      ...  ..  ..  ..  ..  ..  ..  ..  ..   \n","106802          0         0        0   0   1   0   0   0   0   0   1   \n","106803          1         0        1   0   0   1   0   1   0   0   0   \n","106804          1         0        1   0   0   1   0   1   0   0   0   \n","106805          1         1        1   1   0   0   0   1   0   0   0   \n","106806          1         1        1   1   0   0   0   1   0   0   0   \n","\n","                                          tokenized_texts  \n","0       ['[CLS]', '@', 'mig', '##non', '##10', '##44',...  \n","1       ['[CLS]', 'an', 'se', '##be', '##git', '##u', ...  \n","2       ['[CLS]', 'that', 'i', 'can', 'use', 'strong',...  \n","3       ['[CLS]', 's', ':', '/', '/', 't', '.', 'co', ...  \n","4       ['[CLS]', 'de', 'papa', '##i', ',', 'que', '##...  \n","...                                                   ...  \n","106802                                 ['[CLS]', '[SEP]']  \n","106803                                 ['[CLS]', '[SEP]']  \n","106804  ['[CLS]', '@', 'liv', '##ia', '##bell', '##ona...  \n","106805  ['[CLS]', 'questioned', 'my', 'non', '-', 'lin...  \n","106806  ['[CLS]', 'something', 'about', 'it', '.', 'no...  \n","\n","[106807 rows x 16 columns]"]},"metadata":{"tags":[]},"execution_count":168}]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"OMDsFKoEpIOF"},"source":["# OPTION 2: Load Dataframe from disk"]},{"cell_type":"code","metadata":{"id":"KLukrTtXpIOF"},"source":["tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xmRYZfMEpIOF"},"source":["test_file = open('test_tokenized_large_exp.csv')\n","ofile = open('train_tokenized_large_exp.csv')\n","\n","edf = pd.read_csv(ofile, index_col = 0)\n","\n","edf.dropna(inplace= True)\n","#edf, test_df = train_test_split(edf, random_state=2020, test_size=0.10)\n","test_df = pd.read_csv(test_file, index_col=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C1Ji8WXzpIOG"},"source":["test_df = test_df.reset_index(drop = True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WjWR85IZpIOH"},"source":["def fourType(x):\n","    if ((x=='INFJ') | (x=='INFP') | (x=='ENFJ') | (x=='ENFP')):\n","        return 1\n","    elif ((x=='INTJ') | (x=='INTP') | (x=='ENTJ') | (x=='ENTP')):\n","        return 2\n","    elif ((x=='ISFJ') | (x=='ISTJ') | (x=='ESFJ') | (x=='ESTJ')):\n","        return 3\n","    else:\n","        return 0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DFAXFgVWpIOH"},"source":["edf['role'] = edf['type'].map(fourType)\n","test_df['role'] = test_df['type'].map(fourType)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"57ydqQKOpIOI","outputId":"1427938b-9640-4cef-9dd3-7fcb7dd43031"},"source":["df = edf[edf['role']==1].sample(10808, random_state = 34)\n","df = df.append(edf[edf['role']==2].sample(10808, random_state = 35))\n","df = df.append(edf[edf['role']==3].sample(10808, random_state = 35))\n","df = df.append(edf[edf['role']==0].sample(10808, random_state = 35))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>liked_by</th>\n","      <th>text</th>\n","      <th>type</th>\n","      <th>extravert</th>\n","      <th>intuitive</th>\n","      <th>thinking</th>\n","      <th>judging</th>\n","      <th>NT</th>\n","      <th>SF</th>\n","      <th>NF</th>\n","      <th>ST</th>\n","      <th>NJ</th>\n","      <th>NP</th>\n","      <th>SJ</th>\n","      <th>SP</th>\n","      <th>tokenized_texts</th>\n","      <th>role</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>105039</th>\n","      <td>15620292</td>\n","      <td>rUryJJaqPnokay I know you guys like TTRPGs.  h...</td>\n","      <td>INFP</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>['[CLS]', 'ru', '##ry', '##j', '##ja', '##q', ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>52013</th>\n","      <td>3403218160</td>\n","      <td>CiBSdFW2vSreal pokemon merchandise https://t.c...</td>\n","      <td>INFP</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>['[CLS]', 'ci', '##bs', '##df', '##w', '##2', ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>57263</th>\n","      <td>1244901512700030976</td>\n","      <td>it out for Free (link in bio)\\n#brunette #curl...</td>\n","      <td>INFJ</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>['[CLS]', 'it', 'out', 'for', 'free', '(', 'li...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>71092</th>\n","      <td>26871926</td>\n","      <td>l me anh(at)https://t.co/Leb3wLQo3x.We just wa...</td>\n","      <td>ENFJ</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>['[CLS]', 'l', 'me', 'an', '##h', '(', 'at', '...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>96461</th>\n","      <td>6046132</td>\n","      <td>ng it. Anyway the commercially-successful-but-...</td>\n","      <td>INFP</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>['[CLS]', 'ng', 'it', '.', 'anyway', 'the', 'c...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>22249</th>\n","      <td>172118801</td>\n","      <td>MUNICADO https://t.co/QTXWaFw6Oyhttps://t.co/A...</td>\n","      <td>ESFP</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>['[CLS]', 'mu', '##nica', '##do', 'https', ':'...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>58010</th>\n","      <td>491669361</td>\n","      <td>me ambassador for @worldvisioncan. Now we know...</td>\n","      <td>ESFP</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>['[CLS]', 'me', 'ambassador', 'for', '@', 'wor...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>78902</th>\n","      <td>26541394</td>\n","      <td>the developers specifically had CRT monitors i...</td>\n","      <td>ISTP</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>['[CLS]', 'the', 'developers', 'specifically',...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>9532</th>\n","      <td>790271395855003649</td>\n","      <td>ed before my brains melt.  #jiroukyouka #jiro ...</td>\n","      <td>ISFP</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>['[CLS]', 'ed', 'before', 'my', 'brains', 'mel...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>46040</th>\n","      <td>880858425680330752</td>\n","      <td>nt to call him Nines, it's totally okay. https...</td>\n","      <td>ISTP</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>['[CLS]', 'nt', 'to', 'call', 'him', 'nine', '...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>43232 rows × 17 columns</p>\n","</div>"],"text/plain":["                   liked_by  \\\n","105039             15620292   \n","52013            3403218160   \n","57263   1244901512700030976   \n","71092              26871926   \n","96461               6046132   \n","...                     ...   \n","22249             172118801   \n","58010             491669361   \n","78902              26541394   \n","9532     790271395855003649   \n","46040    880858425680330752   \n","\n","                                                     text  type  extravert  \\\n","105039  rUryJJaqPnokay I know you guys like TTRPGs.  h...  INFP          0   \n","52013   CiBSdFW2vSreal pokemon merchandise https://t.c...  INFP          0   \n","57263   it out for Free (link in bio)\\n#brunette #curl...  INFJ          0   \n","71092   l me anh(at)https://t.co/Leb3wLQo3x.We just wa...  ENFJ          1   \n","96461   ng it. Anyway the commercially-successful-but-...  INFP          0   \n","...                                                   ...   ...        ...   \n","22249   MUNICADO https://t.co/QTXWaFw6Oyhttps://t.co/A...  ESFP          1   \n","58010   me ambassador for @worldvisioncan. Now we know...  ESFP          1   \n","78902   the developers specifically had CRT monitors i...  ISTP          0   \n","9532    ed before my brains melt.  #jiroukyouka #jiro ...  ISFP          0   \n","46040   nt to call him Nines, it's totally okay. https...  ISTP          0   \n","\n","        intuitive  thinking  judging  NT  SF  NF  ST  NJ  NP  SJ  SP  \\\n","105039          1         0        0   0   0   1   0   0   1   0   0   \n","52013           1         0        0   0   0   1   0   0   1   0   0   \n","57263           1         0        1   0   0   1   0   1   0   0   0   \n","71092           1         0        1   0   0   1   0   1   0   0   0   \n","96461           1         0        0   0   0   1   0   0   1   0   0   \n","...           ...       ...      ...  ..  ..  ..  ..  ..  ..  ..  ..   \n","22249           0         0        0   0   1   0   0   0   0   0   1   \n","58010           0         0        0   0   1   0   0   0   0   0   1   \n","78902           0         1        0   0   0   0   1   0   0   0   1   \n","9532            0         0        0   0   1   0   0   0   0   0   1   \n","46040           0         1        0   0   0   0   1   0   0   0   1   \n","\n","                                          tokenized_texts  role  \n","105039  ['[CLS]', 'ru', '##ry', '##j', '##ja', '##q', ...     1  \n","52013   ['[CLS]', 'ci', '##bs', '##df', '##w', '##2', ...     1  \n","57263   ['[CLS]', 'it', 'out', 'for', 'free', '(', 'li...     1  \n","71092   ['[CLS]', 'l', 'me', 'an', '##h', '(', 'at', '...     1  \n","96461   ['[CLS]', 'ng', 'it', '.', 'anyway', 'the', 'c...     1  \n","...                                                   ...   ...  \n","22249   ['[CLS]', 'mu', '##nica', '##do', 'https', ':'...     0  \n","58010   ['[CLS]', 'me', 'ambassador', 'for', '@', 'wor...     0  \n","78902   ['[CLS]', 'the', 'developers', 'specifically',...     0  \n","9532    ['[CLS]', 'ed', 'before', 'my', 'brains', 'mel...     0  \n","46040   ['[CLS]', 'nt', 'to', 'call', 'him', 'nine', '...     0  \n","\n","[43232 rows x 17 columns]"]},"metadata":{"tags":[]},"execution_count":61}]},{"cell_type":"code","metadata":{"id":"ttNyQXn0V4ba"},"source":["from ast import literal_eval\n","\n","df = df.sample(frac=1).reset_index(drop=True)\n","tokenized_texts = df['tokenized_texts'].map(literal_eval)\n","\n","test_df = test_df.reset_index(drop = True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mhT9h2kHpIOJ","outputId":"1d3c45b0-f4aa-404c-a604-f212d87510cd"},"source":["tokenized_texts"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0        [[CLS], er, ##y, despite, l, ##w, ##j, ', s, w...\n","1        [[CLS], ph, #, gu, ##hit, ##pina, ##s, https, ...\n","2        [[CLS], h, eli, ##mina, ##das, da, pro, ##va, ...\n","3        [[CLS], p, ;, se, ##m, o, bo, ##a, no, ##ite, ...\n","4        [[CLS], for, an, interview, with, @, maggie, _...\n","                               ...                        \n","43227    [[CLS], https, :, /, /, t, ., co, /, ct, ##ek,...\n","43228    [[CLS], yang, ku, ##rang, pen, ##ting, ., http...\n","43229    [[CLS], tis, i, ’, ve, never, had, a, pizza, w...\n","43230    [[CLS], r, lists, !, !, !, !, thank, you, all,...\n","43231    [[CLS], s, :, /, /, t, ., co, /, f, ##s, ##x, ...\n","Name: tokenized_texts, Length: 43232, dtype: object"]},"metadata":{"tags":[]},"execution_count":63}]},{"cell_type":"code","metadata":{"id":"wywdbBISguFj"},"source":["# Set the maximum sequence length. The longest sequence in our training set is 47, but we'll leave room on the end anyway. \n","# In the original paper, the authors used a length of 512.\n","MAX_LEN = 256"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ko6fHIlAiHm7"},"source":["import os\n","os.environ['KERAS_BACKEND'] = 'tensorflow'\n","from keras.preprocessing.sequence import pad_sequences"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VSaU7DbkgzWh"},"source":["# Pad our input tokens\n","input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n","input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DvR5lSY_pIOM","outputId":"366c181f-b5b0-4e71-ac96-5a19c8f30449"},"source":["input_ids"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[  101,  9413,  2100, ...,  2860,  3501,  5176],\n","       [  101,  6887,  1001, ..., 16770,  1024,  1013],\n","       [  101,  1044, 12005, ...,  4487,  1012,  1001],\n","       ...,\n","       [  101, 22320,  1045, ...,  1996, 11675,  1012],\n","       [  101,  1054,  7201, ...,  2000,  2079,  2007],\n","       [  101,  1055,  1024, ..., 18351,  5622,  2912]])"]},"metadata":{"tags":[]},"execution_count":79}]},{"cell_type":"code","metadata":{"id":"FEUBxUm8g0ov"},"source":["# Create attention masks\n","attention_masks = []\n","\n","# Create a mask of 1s for each token followed by 0s for padding\n","for seq in input_ids:\n","    seq_mask = [float(i>0) for i in seq]\n","    attention_masks.append(seq_mask)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A4QPyBRDiIx1"},"source":["# Use train_test_split to split our data into train and validation sets for training\n","\n","labels = df.role.values\n","train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n","                                                            random_state=2020, test_size=0.01)\n","train_masks, validation_masks, _, _ = train_test_split(attention_masks, input_ids,\n","                                             random_state=2020, test_size=0.01)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"97aegxevtCNU"},"source":["# **OPTION 3: Load v2 Dataframe from disk**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_XpYt1kHtM0M","executionInfo":{"elapsed":6357,"status":"ok","timestamp":1621582049944,"user":{"displayName":"Partha Kadambi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjE3P9W2kYe0-W6DurXX4DIH5pqdXbrfJR4YU_cxQ=s64","userId":"11913997928897283481"},"user_tz":300},"outputId":"ce2a97c5-42d4-4bd9-a1f8-cabc716fad67"},"source":["!pip install transformers"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/43/cfe4ee779bbd6a678ac6a97c5a5cdeb03c35f9eaebbb9720b036680f9a2d/transformers-4.6.1-py3-none-any.whl (2.2MB)\n","\u001b[K     |████████████████████████████████| 2.3MB 6.0MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting tokenizers<0.11,>=0.10.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n","\u001b[K     |████████████████████████████████| 3.3MB 48.0MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Collecting huggingface-hub==0.0.8\n","  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n","\u001b[K     |████████████████████████████████| 901kB 56.6MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (8.0.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Installing collected packages: tokenizers, huggingface-hub, sacremoses, transformers\n","Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.2 transformers-4.6.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0SacbgzktM-I"},"source":["import ast \n","import sklearn\n","import pandas as pd\n","import transformers\n","import torch\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","from ast import literal_eval"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aSska1yJtNAv"},"source":["from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from sklearn.model_selection import train_test_split\n","from transformers import BertTokenizer, BertConfig\n","from transformers import AdamW, BertForSequenceClassification\n","from tqdm import tqdm, trange\n","import pandas as pd\n","import io\n","import pickle"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FuerFygmtNG6","executionInfo":{"elapsed":19050,"status":"ok","timestamp":1621582073678,"user":{"displayName":"Partha Kadambi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjE3P9W2kYe0-W6DurXX4DIH5pqdXbrfJR4YU_cxQ=s64","userId":"11913997928897283481"},"user_tz":300},"outputId":"ee61796d-9e8b-43c4-946a-2985a778c71e"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bimzWjBAtNKv"},"source":["def from_np_array(array_string):\n","    array_string = ','.join(array_string.replace('[ ', '[').split())\n","    return np.array(ast.literal_eval(array_string))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"Sa3o8eiStNPZ","executionInfo":{"elapsed":55751,"status":"ok","timestamp":1621582129425,"user":{"displayName":"Partha Kadambi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjE3P9W2kYe0-W6DurXX4DIH5pqdXbrfJR4YU_cxQ=s64","userId":"11913997928897283481"},"user_tz":300},"outputId":"e407dea2-b1c6-4a05-898c-57b6f38b34e6"},"source":["folder_path = '/content/drive/MyDrive/MBTI_DL_Data/'\n","ofile = open(folder_path + 'Dataframes/master_v2.3.csv', mode = 'r', encoding= 'windows-1252')\n","\n","df = pd.read_pickle(folder_path + 'Dataframes/master_v2.3.csv' )\n","df"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>extravert</th>\n","      <th>follow_back_pic_urls</th>\n","      <th>follow_bios</th>\n","      <th>follow_follows_counts</th>\n","      <th>follow_profile_pic_urls</th>\n","      <th>follow_stats_counts</th>\n","      <th>intuitive</th>\n","      <th>judging</th>\n","      <th>lang</th>\n","      <th>liked_media</th>\n","      <th>liked_tweets</th>\n","      <th>own_media</th>\n","      <th>statuses</th>\n","      <th>thinking</th>\n","      <th>type</th>\n","      <th>user_id</th>\n","      <th>screen_name</th>\n","      <th>name</th>\n","      <th>bio</th>\n","      <th>favorites_count:</th>\n","      <th>statuses_count</th>\n","      <th>follows_count</th>\n","      <th>profile_back_url</th>\n","      <th>profile_pic_url</th>\n","      <th>queried_at</th>\n","      <th>profile_embedding_resnet50</th>\n","      <th>image_array</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.0</td>\n","      <td>['http://abs.twimg.com/images/themes/theme1/bg...</td>\n","      <td>['Leader; follower. Reader; writer. Speaker; l...</td>\n","      <td>[118, 1055, 3, 1989, 69, 335, 654, 980, 98, 39...</td>\n","      <td>['http://pbs.twimg.com/profile_images/64760639...</td>\n","      <td>[87848, 3561, 1468, 54864, 276, 5255, 116451, ...</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>und</td>\n","      <td>['https://pbs.twimg.com/media/Em-45V2VkAAUJqY....</td>\n","      <td>['@M40A3Predator hope you been well. Miss you ...</td>\n","      <td>['https://pbs.twimg.com/media/D4dqPJLVUAAo3Fk....</td>\n","      <td>['https://t.co/lkHBulmhvc', 'We evolved the ap...</td>\n","      <td>1.0</td>\n","      <td>INTP</td>\n","      <td>104066691</td>\n","      <td>M40A3Predator</td>\n","      <td>Logan Keesling</td>\n","      <td>College student. INTP.</td>\n","      <td>1650</td>\n","      <td>6669</td>\n","      <td>400</td>\n","      <td>http://abs.twimg.com/images/themes/theme9/bg.gif</td>\n","      <td>http://pbs.twimg.com/profile_images/1031267728...</td>\n","      <td>2021-05-08 00:08:50.658936</td>\n","      <td>[0.04489563778042793, 2.174224615097046, 0.499...</td>\n","      <td>[[[12, 19, 25], [12, 19, 25], [12, 19, 25], [1...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.0</td>\n","      <td>['http://abs.twimg.com/images/themes/theme1/bg...</td>\n","      <td>['Making people proud to care about gun rights...</td>\n","      <td>[67, 414, 1024, 62, 1, 68, 1703, 681, 85, 4030...</td>\n","      <td>['http://pbs.twimg.com/profile_images/10861406...</td>\n","      <td>[2670, 3487, 30848, 5435, 1229, 10775, 3189, 2...</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>en</td>\n","      <td>['https://pbs.twimg.com/media/E0Aq-wPXIAYhM28....</td>\n","      <td>[\"@hackaday It was 1989. Someone changed the r...</td>\n","      <td>[]</td>\n","      <td>[\"So USA has too many #COVID19 vaccines, while...</td>\n","      <td>1.0</td>\n","      <td>INTP</td>\n","      <td>728747154</td>\n","      <td>LukeDashjr</td>\n","      <td>Luke Dashjr</td>\n","      <td>Roman #Catholic*, husband, father of 7 childre...</td>\n","      <td>32648</td>\n","      <td>58883</td>\n","      <td>139</td>\n","      <td>http://abs.twimg.com/images/themes/theme1/bg.png</td>\n","      <td>http://pbs.twimg.com/profile_images/1299396704...</td>\n","      <td>2021-05-08 00:08:50.671926</td>\n","      <td>[0.4525538980960846, 0.24154025316238403, 0.82...</td>\n","      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.0</td>\n","      <td>['http://abs.twimg.com/images/themes/theme9/bg...</td>\n","      <td>['#FreeMarket think tank advancing real soluti...</td>\n","      <td>[14892, 31, 1456, 2244, 874, 11342, 11, 71, 14...</td>\n","      <td>['http://pbs.twimg.com/profile_images/13777942...</td>\n","      <td>[67741, 858, 59783, 89244, 9986, 10429, 136, 2...</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>en</td>\n","      <td>['https://pbs.twimg.com/media/E0DO_ihWEAANspm....</td>\n","      <td>[\"Patch V1.3.0\\n\\nWe've been listening, and we...</td>\n","      <td>['https://pbs.twimg.com/media/EzTmWO8UUAE-cK-....</td>\n","      <td>['Life isn\\'t fair.\\n\\nThat\\'s not a lament, t...</td>\n","      <td>1.0</td>\n","      <td>INTP</td>\n","      <td>321645158</td>\n","      <td>Sacheverell</td>\n","      <td>Sacheverell</td>\n","      <td>Trust &amp; Safety Lead @vrchat. | Formerly T&amp;S @w...</td>\n","      <td>32461</td>\n","      <td>46164</td>\n","      <td>1274</td>\n","      <td>http://abs.twimg.com/images/themes/theme1/bg.png</td>\n","      <td>http://pbs.twimg.com/profile_images/9959137055...</td>\n","      <td>2021-05-08 00:08:50.678938</td>\n","      <td>[0.8381090760231018, 1.453566312789917, 0.1410...</td>\n","      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.0</td>\n","      <td>[None, None, 'http://abs.twimg.com/images/them...</td>\n","      <td>['NAME will be announced closer to launch - HE...</td>\n","      <td>[1, 1376, 6122, 601, 1299, 690, 785, 340, 1079...</td>\n","      <td>['http://pbs.twimg.com/profile_images/13842164...</td>\n","      <td>[6, 8753, 9855, 13930, 36826, 131, 2888, 9751,...</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>en</td>\n","      <td>['https://pbs.twimg.com/amplify_video_thumb/12...</td>\n","      <td>['It’s The Oscars tonight! I wasn’t invited. W...</td>\n","      <td>['https://pbs.twimg.com/ext_tw_video_thumb/138...</td>\n","      <td>['Happy puppies 🥺🥰 https://t.co/O6FOXQQFtF', '...</td>\n","      <td>1.0</td>\n","      <td>INTP</td>\n","      <td>346419306</td>\n","      <td>Blondiettv</td>\n","      <td>Shan</td>\n","      <td>tired. | @Twitch Partner |</td>\n","      <td>24435</td>\n","      <td>24809</td>\n","      <td>1092</td>\n","      <td>http://abs.twimg.com/images/themes/theme19/bg.gif</td>\n","      <td>http://pbs.twimg.com/profile_images/1377152197...</td>\n","      <td>2021-05-08 00:08:50.688448</td>\n","      <td>[0.05482032522559166, 1.4306827783584595, 0.58...</td>\n","      <td>[[[189, 185, 173], [189, 185, 173], [189, 185,...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.0</td>\n","      <td>[None, 'http://abs.twimg.com/images/themes/the...</td>\n","      <td>['Occasional funny clips from games I recorded...</td>\n","      <td>[2, 687, 37, 408, 360, 765, 975, 239, 360, 492...</td>\n","      <td>['http://pbs.twimg.com/profile_images/13360189...</td>\n","      <td>[2, 0, 6557, 1348, 2898, 6999, 37687, 1219, 89...</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>en</td>\n","      <td>['https://pbs.twimg.com/media/EwkPYfNVIAQU7Vs....</td>\n","      <td>['\"Oh I\\'m not very good at that game, but sur...</td>\n","      <td>['https://pbs.twimg.com/media/Ew4wixCW8AEBwCn....</td>\n","      <td>['long time no see\\nI started a new job last w...</td>\n","      <td>1.0</td>\n","      <td>INTP</td>\n","      <td>709345926</td>\n","      <td>AlexisWolfy</td>\n","      <td>AlexWolfy</td>\n","      <td>24 | artist | sonic and mario are pretty cool ...</td>\n","      <td>37507</td>\n","      <td>6800</td>\n","      <td>435</td>\n","      <td>http://abs.twimg.com/images/themes/theme1/bg.png</td>\n","      <td>http://pbs.twimg.com/profile_images/1382724888...</td>\n","      <td>2021-05-08 00:08:50.696464</td>\n","      <td>[0.08659341186285019, 0.6954305171966553, 0.04...</td>\n","      <td>[[[70, 47, 41], [70, 47, 41], [70, 47, 41], [7...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>3843</th>\n","      <td>1.0</td>\n","      <td>[None, None, None, None, 'http://abs.twimg.com...</td>\n","      <td>['Scans/edits of official items from @TXT_bigh...</td>\n","      <td>[7, 11, 276, 355, 2953, 954, 3, 87, 4, 9, 113,...</td>\n","      <td>['http://pbs.twimg.com/profile_images/13258167...</td>\n","      <td>[1257, 212, 23986, 2113, 3219, 60807, 1410, 14...</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>th</td>\n","      <td>['https://pbs.twimg.com/ext_tw_video_thumb/138...</td>\n","      <td>['BUTTER // @BTS_twt // MAY 21\\n\\nPRE-SAVE/PRE...</td>\n","      <td>['https://pbs.twimg.com/media/Esd9SSBUwAcfwFW....</td>\n","      <td>['ส่วนของนี่เป็นอดัมฟอลแล้วมิ้วฉันแน่ๆ ตอนนั้น...</td>\n","      <td>0.0</td>\n","      <td>ESFJ</td>\n","      <td>590000506</td>\n","      <td>cherilnaey</td>\n","      <td>CN너이 | ꪔ̤̮</td>\n","      <td>ESFJ | เหนยน่ะ : my euphoria jungkook❥ EN/TH O...</td>\n","      <td>30834</td>\n","      <td>40699</td>\n","      <td>303</td>\n","      <td>http://abs.twimg.com/images/themes/theme18/bg.gif</td>\n","      <td>http://pbs.twimg.com/profile_images/1302761904...</td>\n","      <td>2021-05-08 00:16:12.807363</td>\n","      <td>[0.024641845375299454, 1.0048145055770874, 0.0...</td>\n","      <td>[[[255, 164, 112], [255, 163, 111], [255, 161,...</td>\n","    </tr>\n","    <tr>\n","      <th>3844</th>\n","      <td>1.0</td>\n","      <td>[None, None, None, None, None, None, None, Non...</td>\n","      <td>['l’m boy ,', 'ليفاي عم الكل|#Levi هامور سابقا...</td>\n","      <td>[76, 151, 461, 58, 13, 157, 635, 1113, 548, 65...</td>\n","      <td>['http://pbs.twimg.com/profile_images/12776981...</td>\n","      <td>[16841, 3777, 16335, 1097, 590, 4035, 57431, 3...</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>ar</td>\n","      <td>['https://pbs.twimg.com/media/Ez_L_WdVkAghECU....</td>\n","      <td>['@moh_q6 اهليين كارلوس🥺💜', '@moh_q6 ههههههههه...</td>\n","      <td>['https://pbs.twimg.com/ext_tw_video_thumb/138...</td>\n","      <td>['محد طلع وشاف بروق ورعود ورجع البيت 😭💔💔', 'شا...</td>\n","      <td>0.0</td>\n","      <td>ESFJ</td>\n","      <td>884119350445305856</td>\n","      <td>moh_q6</td>\n","      <td>‏كارلــــوس ❣︎ 😌</td>\n","      <td>Cute person, gamer , I am 16 years old .| I lo...</td>\n","      <td>14631</td>\n","      <td>18694</td>\n","      <td>54</td>\n","      <td>NaN</td>\n","      <td>http://pbs.twimg.com/profile_images/1380068998...</td>\n","      <td>2021-05-08 00:16:13.004061</td>\n","      <td>[0.5938600301742554, 0.9714032411575317, 0.139...</td>\n","      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n","    </tr>\n","    <tr>\n","      <th>3845</th>\n","      <td>1.0</td>\n","      <td>['http://abs.twimg.com/images/themes/theme1/bg...</td>\n","      <td>['Updates from the MA Publishing course at @lc...</td>\n","      <td>[353, 506, 997, 232, 652, 1184, 738, 1128, 100...</td>\n","      <td>['http://pbs.twimg.com/profile_images/13688892...</td>\n","      <td>[758, 1458, 1872, 776, 3756, 2228, 1394, 5814,...</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>en</td>\n","      <td>['https://pbs.twimg.com/media/C7DaUqPU0AE4ODU....</td>\n","      <td>['One punny anti-Trump sign spotted in London ...</td>\n","      <td>['https://pbs.twimg.com/media/EI1tiXNW4AAJvBf....</td>\n","      <td>['I knew immediately where the photo of Task #...</td>\n","      <td>0.0</td>\n","      <td>ESFJ</td>\n","      <td>15939890</td>\n","      <td>chubacca</td>\n","      <td>Alyson Chu</td>\n","      <td>ESFJ, books, food, feminism, and YouTube. Reci...</td>\n","      <td>188</td>\n","      <td>1985</td>\n","      <td>228</td>\n","      <td>http://abs.twimg.com/images/themes/theme5/bg.gif</td>\n","      <td>http://pbs.twimg.com/profile_images/7166585412...</td>\n","      <td>2021-05-08 00:16:13.203962</td>\n","      <td>[0.4700876474380493, 0.9354822635650635, 1.269...</td>\n","      <td>[[[239, 238, 236], [239, 238, 236], [240, 239,...</td>\n","    </tr>\n","    <tr>\n","      <th>3846</th>\n","      <td>1.0</td>\n","      <td>[None, None, 'http://abs.twimg.com/images/them...</td>\n","      <td>['(She/her)⭐️ Wannabe artist with a scientific...</td>\n","      <td>[236, 1, 202, 23, 2, 690, 93, 10, 128, 591, 38...</td>\n","      <td>['http://pbs.twimg.com/profile_images/13714164...</td>\n","      <td>[150, 12231, 53673, 2151, 17913, 257, 4294, 14...</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>es</td>\n","      <td>['https://pbs.twimg.com/media/EqmF4x0XcAAuBgq....</td>\n","      <td>['🚨 2020 found dead in electrical\\n\\nready for...</td>\n","      <td>[]</td>\n","      <td>['4 años ya de este tuit, amazing.\\nY mi condi...</td>\n","      <td>0.0</td>\n","      <td>ESFJ</td>\n","      <td>757759104</td>\n","      <td>SunnyDeKnight</td>\n","      <td>Sunny ~ ☼</td>\n","      <td>[Esp/Eng] 26. ♀. In love with Anime/Manga, vid...</td>\n","      <td>6384</td>\n","      <td>100502</td>\n","      <td>361</td>\n","      <td>http://abs.twimg.com/images/themes/theme4/bg.gif</td>\n","      <td>http://pbs.twimg.com/profile_images/1290606759...</td>\n","      <td>2021-05-08 00:16:13.397851</td>\n","      <td>[0.5486451983451843, 0.2936170995235443, 0.260...</td>\n","      <td>[[[0, 139, 100], [0, 139, 100], [0, 138, 102],...</td>\n","    </tr>\n","    <tr>\n","      <th>3847</th>\n","      <td>1.0</td>\n","      <td>['http://abs.twimg.com/images/themes/theme1/bg...</td>\n","      <td>['A maior fonte de informações sobre @twentyon...</td>\n","      <td>[120, 595, 81, 31, 1747, 86, 2071, 634, 273, 1...</td>\n","      <td>['http://pbs.twimg.com/profile_images/13792414...</td>\n","      <td>[17989, 5094, 1397, 1, 75588, 28, 64368, 16472...</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>pt</td>\n","      <td>['https://pbs.twimg.com/ext_tw_video_thumb/137...</td>\n","      <td>['@ArthurMcvicious @petalsforlau @xvikkisx doi...</td>\n","      <td>['https://pbs.twimg.com/media/E0BBkrqWQAIr0Zs....</td>\n","      <td>['Hoje peguei ela na praça https://t.co/stBQOm...</td>\n","      <td>0.0</td>\n","      <td>ESFJ</td>\n","      <td>815939489340256257</td>\n","      <td>petalsforlau</td>\n","      <td>lau</td>\n","      <td>reclamações constantes \\n\\nESFJ (ela/dela)</td>\n","      <td>2071</td>\n","      <td>14311</td>\n","      <td>197</td>\n","      <td>http://abs.twimg.com/images/themes/theme1/bg.png</td>\n","      <td>http://pbs.twimg.com/profile_images/1382468672...</td>\n","      <td>2021-05-08 00:16:13.597156</td>\n","      <td>[0.13540582358837128, 1.6893001794815063, 0.61...</td>\n","      <td>[[[124, 131, 141], [125, 132, 142], [125, 132,...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3848 rows × 27 columns</p>\n","</div>"],"text/plain":["      extravert  ...                                        image_array\n","0           0.0  ...  [[[12, 19, 25], [12, 19, 25], [12, 19, 25], [1...\n","1           0.0  ...  [[[255, 255, 255], [255, 255, 255], [255, 255,...\n","2           0.0  ...  [[[255, 255, 255], [255, 255, 255], [255, 255,...\n","3           0.0  ...  [[[189, 185, 173], [189, 185, 173], [189, 185,...\n","4           0.0  ...  [[[70, 47, 41], [70, 47, 41], [70, 47, 41], [7...\n","...         ...  ...                                                ...\n","3843        1.0  ...  [[[255, 164, 112], [255, 163, 111], [255, 161,...\n","3844        1.0  ...  [[[255, 255, 255], [255, 255, 255], [255, 255,...\n","3845        1.0  ...  [[[239, 238, 236], [239, 238, 236], [240, 239,...\n","3846        1.0  ...  [[[0, 139, 100], [0, 139, 100], [0, 138, 102],...\n","3847        1.0  ...  [[[124, 131, 141], [125, 132, 142], [125, 132,...\n","\n","[3848 rows x 27 columns]"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"eb-_fnHBtNYd"},"source":["adf = df[['extravert', 'thinking', 'intuitive', 'judging', 'lang', 'liked_tweets']]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WkICI2I7tcxk","executionInfo":{"elapsed":17,"status":"ok","timestamp":1621582129426,"user":{"displayName":"Partha Kadambi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjE3P9W2kYe0-W6DurXX4DIH5pqdXbrfJR4YU_cxQ=s64","userId":"11913997928897283481"},"user_tz":300},"outputId":"aac87080-7c50-441f-e4fc-776e3daa7516"},"source":["adf['liked_tweets']\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0       ['@M40A3Predator hope you been well. Miss you ...\n","1       [\"@hackaday It was 1989. Someone changed the r...\n","2       [\"Patch V1.3.0\\n\\nWe've been listening, and we...\n","3       ['It’s The Oscars tonight! I wasn’t invited. W...\n","4       ['\"Oh I\\'m not very good at that game, but sur...\n","                              ...                        \n","3843    ['BUTTER // @BTS_twt // MAY 21\\n\\nPRE-SAVE/PRE...\n","3844    ['@moh_q6 اهليين كارلوس🥺💜', '@moh_q6 ههههههههه...\n","3845    ['One punny anti-Trump sign spotted in London ...\n","3846    ['🚨 2020 found dead in electrical\\n\\nready for...\n","3847    ['@ArthurMcvicious @petalsforlau @xvikkisx doi...\n","Name: liked_tweets, Length: 3848, dtype: object"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"IeMqNY6RCgBZ"},"source":["def trim_liked(x):\n","  r = ''\n","  s = x.split()\n","  for word in s:\n","    if (len(word)<20) and (word[0] != '@'):\n","      r+= ' ' + word\n","      \n","  return r"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":180},"id":"x37AH1hnCEv1","executionInfo":{"status":"error","timestamp":1621658280468,"user_tz":300,"elapsed":135,"user":{"displayName":"Partha Kadambi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjE3P9W2kYe0-W6DurXX4DIH5pqdXbrfJR4YU_cxQ=s64","userId":"11913997928897283481"}},"outputId":"8df9da5a-0ac8-48ba-9255-bca53a41b43e"},"source":["adf['liked_tweets'] = adf['liked_tweets'].apply(lambda x: '. '.join(ast.literal_eval(x)))\n","adf['liked_tweets'] = adf['liked_tweets'].apply(lambda x: trim_liked(x))"],"execution_count":4,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-d03ac6433443>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0madf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'liked_tweets'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'liked_tweets'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'. '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mliteral_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0madf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'liked_tweets'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'liked_tweets'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrim_liked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'adf' is not defined"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":163},"id":"qACME6fwXT9J","executionInfo":{"status":"error","timestamp":1621658270650,"user_tz":300,"elapsed":137,"user":{"displayName":"Partha Kadambi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjE3P9W2kYe0-W6DurXX4DIH5pqdXbrfJR4YU_cxQ=s64","userId":"11913997928897283481"}},"outputId":"32dc63ca-0e69-4271-a966-986b94d04fd6"},"source":["adf"],"execution_count":2,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-eee85bca3608>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0madf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'adf' is not defined"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":231},"id":"U1TJKKELtc0Y","executionInfo":{"status":"error","timestamp":1621658274350,"user_tz":300,"elapsed":165,"user":{"displayName":"Partha Kadambi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjE3P9W2kYe0-W6DurXX4DIH5pqdXbrfJR4YU_cxQ=s64","userId":"11913997928897283481"}},"outputId":"f0c18b6d-0ba9-4da9-af01-0c75d07f720a"},"source":["target_mode = 'intuitive'\n","\n","sample_size = min(len(adf[adf[target_mode]==1]), len(adf[adf[target_mode]==0] ))\n","\n","typeA = adf[adf[target_mode]==1].sample(sample_size)\n","typeB = adf[adf[target_mode]==0].sample(sample_size)\n","sample_size"],"execution_count":3,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-052dffa733c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtarget_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'intuitive'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msample_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0madf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_mode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0madf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_mode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtypeA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0madf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_mode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'adf' is not defined"]}]},{"cell_type":"code","metadata":{"id":"6v0_vTNk4Plf","colab":{"base_uri":"https://localhost:8080/","height":231},"executionInfo":{"status":"error","timestamp":1621658289169,"user_tz":300,"elapsed":130,"user":{"displayName":"Partha Kadambi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjE3P9W2kYe0-W6DurXX4DIH5pqdXbrfJR4YU_cxQ=s64","userId":"11913997928897283481"}},"outputId":"44488c71-dd39-45cd-8532-2eec4d1cbb05"},"source":["data_A = typeA[['liked_tweets', target_mode]]\n","data_B = typeB[['liked_tweets', target_mode]]\n","\n","data_df = data_A.append(data_B).sample(frac = 1, random_state = 42).reset_index(drop = True)\n","\n","train_df, test_df = train_test_split(data_df, random_state= 1729, test_size= 0.10)\n","\n","train_df.reset_index(inplace = True, drop = True)\n","test_df.reset_index(inplace = True, drop = True)"],"execution_count":5,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-e97ffe443f0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_A\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtypeA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'liked_tweets'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_mode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdata_B\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtypeB\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'liked_tweets'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_mode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdata_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_B\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'typeA' is not defined"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"9P0bVc7hEwFa","executionInfo":{"elapsed":9,"status":"ok","timestamp":1621582141247,"user":{"displayName":"Partha Kadambi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjE3P9W2kYe0-W6DurXX4DIH5pqdXbrfJR4YU_cxQ=s64","userId":"11913997928897283481"},"user_tz":300},"outputId":"3693c505-f99e-4eca-cc8a-57b05525bd49"},"source":["train_df"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>liked_tweets</th>\n","      <th>intuitive</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Thanks to for sharing this inspiring message....</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2018 / 2021 top personagens chatos de dorama ...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>拍了几十遍！ 长图 请 女孩子们 一定不要 两个人住酒店 也不要一个人单独住酒店。 Cai...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>I am heartbroken to announce that my Dad, my ...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Good morning everyone from me and my ...........</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2819</th>\n","      <td>Stayed tuned for client announcements, illust...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>2820</th>\n","      <td>Open your mind... Danchou has been working ou...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>2821</th>\n","      <td>There’s a lot of people who have absolutely n...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>2822</th>\n","      <td>ส่งหน่วย seal เข้าไปละฮะ รอดูผล 5555. อดีตหุ้...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2823</th>\n","      <td>I love Nier. This ancient talking tome is awo...</td>\n","      <td>1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2824 rows × 2 columns</p>\n","</div>"],"text/plain":["                                           liked_tweets  intuitive\n","0      Thanks to for sharing this inspiring message....        1.0\n","1      2018 / 2021 top personagens chatos de dorama ...        0.0\n","2      拍了几十遍！ 长图 请 女孩子们 一定不要 两个人住酒店 也不要一个人单独住酒店。 Cai...        0.0\n","3      I am heartbroken to announce that my Dad, my ...        0.0\n","4      Good morning everyone from me and my ...........        1.0\n","...                                                 ...        ...\n","2819   Stayed tuned for client announcements, illust...        1.0\n","2820   Open your mind... Danchou has been working ou...        1.0\n","2821   There’s a lot of people who have absolutely n...        1.0\n","2822   ส่งหน่วย seal เข้าไปละฮะ รอดูผล 5555. อดีตหุ้...        0.0\n","2823   I love Nier. This ancient talking tome is awo...        1.0\n","\n","[2824 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"EnIk-dkRDhfo","executionInfo":{"elapsed":274,"status":"ok","timestamp":1621582141514,"user":{"displayName":"Partha Kadambi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjE3P9W2kYe0-W6DurXX4DIH5pqdXbrfJR4YU_cxQ=s64","userId":"11913997928897283481"},"user_tz":300},"outputId":"e26eab37-384a-406a-f4be-1f8a8561c112"},"source":["test_df"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>liked_tweets</th>\n","      <th>intuitive</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>I am 30 minutes into home schooling my 6 year...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1/ I'm in the middle of a skincare deep dive ...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Can’t wait to chat with you on my Onlyfans! 💋...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>eu. mas esse não é o papel de qualquer ator? ...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>I BEAT Stage 3 Colon Cancer in the middle of ...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>309</th>\n","      <td>This is the best thing in my day.. LOL! Pee i...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>310</th>\n","      <td>mood removing ram from a computer while it’s ...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>311</th>\n","      <td>Here's some snaps of some of my favorite stre...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>312</th>\n","      <td>Become ungovernable Lizzo is so gorgeous omg ...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>313</th>\n","      <td>nunca levei o git gud tão a sério quanto tô l...</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>314 rows × 2 columns</p>\n","</div>"],"text/plain":["                                          liked_tweets  intuitive\n","0     I am 30 minutes into home schooling my 6 year...        0.0\n","1     1/ I'm in the middle of a skincare deep dive ...        1.0\n","2     Can’t wait to chat with you on my Onlyfans! 💋...        0.0\n","3     eu. mas esse não é o papel de qualquer ator? ...        0.0\n","4     I BEAT Stage 3 Colon Cancer in the middle of ...        1.0\n","..                                                 ...        ...\n","309   This is the best thing in my day.. LOL! Pee i...        0.0\n","310   mood removing ram from a computer while it’s ...        1.0\n","311   Here's some snaps of some of my favorite stre...        1.0\n","312   Become ungovernable Lizzo is so gorgeous omg ...        1.0\n","313   nunca levei o git gud tão a sério quanto tô l...        0.0\n","\n","[314 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"nV5N19Tj4YQ6"},"source":["def expand_frame(df, length):\n","    ndf = pd.DataFrame()\n","    cdf = df.copy(deep= True)\n","    cdf['split_tweets'] = cdf['liked_tweets'].apply(lambda x: x.split())\n","    print('1')\n","    for i in range(0, 21):\n","        ccdf = cdf[cdf['split_tweets'].apply(lambda x: (len(x) > (0 + i * length)) == 1)]\n","        ccdf['split_tweets'] = ccdf['split_tweets'].apply(lambda x: x[0 + length*i : length * (i+1)])\n","        ndf = ndf.append(ccdf)  \n","        ndf.reset_index(drop=True, inplace= True)                                     \n","\n","    print('1') \n","    ndf['liked_tweets'] = ndf['split_tweets'].apply(lambda x: ' '.join(x))\n","    return ndf"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":555},"id":"YdZ47H9mBaW8","executionInfo":{"elapsed":2928,"status":"ok","timestamp":1621582144438,"user":{"displayName":"Partha Kadambi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjE3P9W2kYe0-W6DurXX4DIH5pqdXbrfJR4YU_cxQ=s64","userId":"11913997928897283481"},"user_tz":300},"outputId":"ea010aa2-71f6-4f1f-df3d-111999480677"},"source":["train_df = expand_frame(train_df, 512)\n","train_df = train_df.sample(frac = 1, random_state= 153)\n","train_df.reset_index(inplace= True, drop = True)\n","train_df"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \n"],"name":"stderr"},{"output_type":"stream","text":["1\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>liked_tweets</th>\n","      <th>intuitive</th>\n","      <th>split_tweets</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>your happiness, and sad for your sadness. They...</td>\n","      <td>0.0</td>\n","      <td>[your, happiness,, and, sad, for, your, sadnes...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>to have start-up like this from India.. Thank ...</td>\n","      <td>1.0</td>\n","      <td>[to, have, start-up, like, this, from, India.....</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>morro de medo de não conseguir trabalho nem na...</td>\n","      <td>1.0</td>\n","      <td>[morro, de, medo, de, não, conseguir, trabalho...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>it's my best book yet.. Cause, attacking someo...</td>\n","      <td>1.0</td>\n","      <td>[it's, my, best, book, yet.., Cause,, attackin...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Yo respondiendo los mensajes de mis amigos des...</td>\n","      <td>0.0</td>\n","      <td>[Yo, respondiendo, los, mensajes, de, mis, ami...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>32851</th>\n","      <td>give to others. No matter how his appearance c...</td>\n","      <td>0.0</td>\n","      <td>[give, to, others., No, matter, how, his, appe...</td>\n","    </tr>\n","    <tr>\n","      <th>32852</th>\n","      <td>Connecticut to register to join Sustainable CT...</td>\n","      <td>0.0</td>\n","      <td>[Connecticut, to, register, to, join, Sustaina...</td>\n","    </tr>\n","    <tr>\n","      <th>32853</th>\n","      <td>me 🦦 buying a set when i get paid this week so...</td>\n","      <td>1.0</td>\n","      <td>[me, 🦦, buying, a, set, when, i, get, paid, th...</td>\n","    </tr>\n","    <tr>\n","      <th>32854</th>\n","      <td>food but … books? Feels like the pandemic fast...</td>\n","      <td>1.0</td>\n","      <td>[food, but, …, books?, Feels, like, the, pande...</td>\n","    </tr>\n","    <tr>\n","      <th>32855</th>\n","      <td>marketing by TY4RT, &amp;gt; Data #Storytelling: E...</td>\n","      <td>1.0</td>\n","      <td>[marketing, by, TY4RT,, &amp;gt;, Data, #Storytell...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>32856 rows × 3 columns</p>\n","</div>"],"text/plain":["                                            liked_tweets  ...                                       split_tweets\n","0      your happiness, and sad for your sadness. They...  ...  [your, happiness,, and, sad, for, your, sadnes...\n","1      to have start-up like this from India.. Thank ...  ...  [to, have, start-up, like, this, from, India.....\n","2      morro de medo de não conseguir trabalho nem na...  ...  [morro, de, medo, de, não, conseguir, trabalho...\n","3      it's my best book yet.. Cause, attacking someo...  ...  [it's, my, best, book, yet.., Cause,, attackin...\n","4      Yo respondiendo los mensajes de mis amigos des...  ...  [Yo, respondiendo, los, mensajes, de, mis, ami...\n","...                                                  ...  ...                                                ...\n","32851  give to others. No matter how his appearance c...  ...  [give, to, others., No, matter, how, his, appe...\n","32852  Connecticut to register to join Sustainable CT...  ...  [Connecticut, to, register, to, join, Sustaina...\n","32853  me 🦦 buying a set when i get paid this week so...  ...  [me, 🦦, buying, a, set, when, i, get, paid, th...\n","32854  food but … books? Feels like the pandemic fast...  ...  [food, but, …, books?, Feels, like, the, pande...\n","32855  marketing by TY4RT, &gt; Data #Storytelling: E...  ...  [marketing, by, TY4RT,, &gt;, Data, #Storytell...\n","\n","[32856 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"4dDNlpDnNEQN","executionInfo":{"elapsed":10,"status":"ok","timestamp":1621582144438,"user":{"displayName":"Partha Kadambi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjE3P9W2kYe0-W6DurXX4DIH5pqdXbrfJR4YU_cxQ=s64","userId":"11913997928897283481"},"user_tz":300},"outputId":"99225058-b400-439b-90d6-719421d9c583"},"source":["train_df"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>liked_tweets</th>\n","      <th>intuitive</th>\n","      <th>split_tweets</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>your happiness, and sad for your sadness. They...</td>\n","      <td>0.0</td>\n","      <td>[your, happiness,, and, sad, for, your, sadnes...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>to have start-up like this from India.. Thank ...</td>\n","      <td>1.0</td>\n","      <td>[to, have, start-up, like, this, from, India.....</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>morro de medo de não conseguir trabalho nem na...</td>\n","      <td>1.0</td>\n","      <td>[morro, de, medo, de, não, conseguir, trabalho...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>it's my best book yet.. Cause, attacking someo...</td>\n","      <td>1.0</td>\n","      <td>[it's, my, best, book, yet.., Cause,, attackin...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Yo respondiendo los mensajes de mis amigos des...</td>\n","      <td>0.0</td>\n","      <td>[Yo, respondiendo, los, mensajes, de, mis, ami...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>32851</th>\n","      <td>give to others. No matter how his appearance c...</td>\n","      <td>0.0</td>\n","      <td>[give, to, others., No, matter, how, his, appe...</td>\n","    </tr>\n","    <tr>\n","      <th>32852</th>\n","      <td>Connecticut to register to join Sustainable CT...</td>\n","      <td>0.0</td>\n","      <td>[Connecticut, to, register, to, join, Sustaina...</td>\n","    </tr>\n","    <tr>\n","      <th>32853</th>\n","      <td>me 🦦 buying a set when i get paid this week so...</td>\n","      <td>1.0</td>\n","      <td>[me, 🦦, buying, a, set, when, i, get, paid, th...</td>\n","    </tr>\n","    <tr>\n","      <th>32854</th>\n","      <td>food but … books? Feels like the pandemic fast...</td>\n","      <td>1.0</td>\n","      <td>[food, but, …, books?, Feels, like, the, pande...</td>\n","    </tr>\n","    <tr>\n","      <th>32855</th>\n","      <td>marketing by TY4RT, &amp;gt; Data #Storytelling: E...</td>\n","      <td>1.0</td>\n","      <td>[marketing, by, TY4RT,, &amp;gt;, Data, #Storytell...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>32856 rows × 3 columns</p>\n","</div>"],"text/plain":["                                            liked_tweets  ...                                       split_tweets\n","0      your happiness, and sad for your sadness. They...  ...  [your, happiness,, and, sad, for, your, sadnes...\n","1      to have start-up like this from India.. Thank ...  ...  [to, have, start-up, like, this, from, India.....\n","2      morro de medo de não conseguir trabalho nem na...  ...  [morro, de, medo, de, não, conseguir, trabalho...\n","3      it's my best book yet.. Cause, attacking someo...  ...  [it's, my, best, book, yet.., Cause,, attackin...\n","4      Yo respondiendo los mensajes de mis amigos des...  ...  [Yo, respondiendo, los, mensajes, de, mis, ami...\n","...                                                  ...  ...                                                ...\n","32851  give to others. No matter how his appearance c...  ...  [give, to, others., No, matter, how, his, appe...\n","32852  Connecticut to register to join Sustainable CT...  ...  [Connecticut, to, register, to, join, Sustaina...\n","32853  me 🦦 buying a set when i get paid this week so...  ...  [me, 🦦, buying, a, set, when, i, get, paid, th...\n","32854  food but … books? Feels like the pandemic fast...  ...  [food, but, …, books?, Feels, like, the, pande...\n","32855  marketing by TY4RT, &gt; Data #Storytelling: E...  ...  [marketing, by, TY4RT,, &gt;, Data, #Storytell...\n","\n","[32856 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"8NvX-SKwHPBc","executionInfo":{"elapsed":9,"status":"ok","timestamp":1621582144439,"user":{"displayName":"Partha Kadambi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjE3P9W2kYe0-W6DurXX4DIH5pqdXbrfJR4YU_cxQ=s64","userId":"11913997928897283481"},"user_tz":300},"outputId":"f25a5253-a89a-4a86-d2da-6435b546d225"},"source":["test_df"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>liked_tweets</th>\n","      <th>intuitive</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>I am 30 minutes into home schooling my 6 year...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1/ I'm in the middle of a skincare deep dive ...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Can’t wait to chat with you on my Onlyfans! 💋...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>eu. mas esse não é o papel de qualquer ator? ...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>I BEAT Stage 3 Colon Cancer in the middle of ...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>309</th>\n","      <td>This is the best thing in my day.. LOL! Pee i...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>310</th>\n","      <td>mood removing ram from a computer while it’s ...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>311</th>\n","      <td>Here's some snaps of some of my favorite stre...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>312</th>\n","      <td>Become ungovernable Lizzo is so gorgeous omg ...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>313</th>\n","      <td>nunca levei o git gud tão a sério quanto tô l...</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>314 rows × 2 columns</p>\n","</div>"],"text/plain":["                                          liked_tweets  intuitive\n","0     I am 30 minutes into home schooling my 6 year...        0.0\n","1     1/ I'm in the middle of a skincare deep dive ...        1.0\n","2     Can’t wait to chat with you on my Onlyfans! 💋...        0.0\n","3     eu. mas esse não é o papel de qualquer ator? ...        0.0\n","4     I BEAT Stage 3 Colon Cancer in the middle of ...        1.0\n","..                                                 ...        ...\n","309   This is the best thing in my day.. LOL! Pee i...        0.0\n","310   mood removing ram from a computer while it’s ...        1.0\n","311   Here's some snaps of some of my favorite stre...        1.0\n","312   Become ungovernable Lizzo is so gorgeous omg ...        1.0\n","313   nunca levei o git gud tão a sério quanto tô l...        0.0\n","\n","[314 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":297},"id":"DjXc-tcZtc5u","executionInfo":{"elapsed":1119,"status":"ok","timestamp":1621582145550,"user":{"displayName":"Partha Kadambi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjE3P9W2kYe0-W6DurXX4DIH5pqdXbrfJR4YU_cxQ=s64","userId":"11913997928897283481"},"user_tz":300},"outputId":"472a010d-6b92-4710-c7d3-f96e12572395"},"source":["import seaborn as sns\n","\n","sns.histplot(train_df['liked_tweets'].apply(lambda x: len(x.split())))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7f146839e590>"]},"metadata":{"tags":[]},"execution_count":19},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"2_g0QGY3tc_1"},"source":["# Create sentence and label lists\n","sentences = train_df.liked_tweets.values\n","\n","# We need to add special tokens at the beginning and end of each sentence for BERT to work properly\n","sentences = [\"[CLS] \" + str(sentence) + \" [SEP]\" for sentence in sentences]\n","labels = train_df.intuitive.values"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":218,"referenced_widgets":["406e1951535744418ebd0c8d920eb35d","6c95393dd2194b57a1b0db7dfae293f3","b681080658ba4f21902ad86602a778dd","16e03c50e6ab4d24b73146bb1df8210d","82dcb7d9586b4e4e9c64b1bdce94424e","92c102a78ef5466394ea9ba68f2c1805","be7391940c754dc3a7957d2b960ad0e2","b103013777b3486c8ea0365ad830b90f","1ed0da8fbdd242389131039e01a54a1b","3c837d15c06c4e2fa489e4cbd32a4f6f","607e3f9eb38240b0ba46fb621342f0cd","c1e364f15ec74b83b56b981d4a9da869","ccfe190c96774a16a97dab15c053adca","57f2de64e2ec41d2a20afb18a5c619c6","11895b23c5a04ac6947ab6e234e22f37","dacf18af80634c6ab2d2974b15935ad4","d43ffdd2c54f41df9afd92cb237186fa","4b93e295c0454d19a6ff1c24c049a1a1","0b01146831084ac29ab5e5183aa9b5c2","31a972de30ae49c89e470e84dd89ed40","bfd38dcc4148475d976c52684c8a6c2b","b6440b2ee582462faf1b1327aa268a14","88edfa01496340ee904bd8da0fe20368","74dfebdb7bb14dd2b66c0ea877008ec5"]},"id":"lgcDePZPtdCJ","executionInfo":{"elapsed":333977,"status":"ok","timestamp":1621582482429,"user":{"displayName":"Partha Kadambi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjE3P9W2kYe0-W6DurXX4DIH5pqdXbrfJR4YU_cxQ=s64","userId":"11913997928897283481"},"user_tz":300},"outputId":"8b66aae3-98b3-4a53-aff1-e65cc8e49cd5"},"source":["tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n","\n","tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n","print (\"Tokenize the first sentence:\")\n","print (tokenized_texts[0])"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"406e1951535744418ebd0c8d920eb35d","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1ed0da8fbdd242389131039e01a54a1b","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d43ffdd2c54f41df9afd92cb237186fa","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Tokenize the first sentence:\n","['[CLS]', 'your', 'happiness', ',', 'and', 'sad', 'for', 'your', 'sadness', '.', 'they', '’', 're', 'the', 'ones', 'who', 'deserve', 'special', 'places', 'in', 'your', 'heart', '.', '”', 'finally', 'got', 'his', 'own', 'room', '!', 'se', '##jak', '5', 'hari', 'y', '##g', 'lal', '##u', ',', 'rider', 'shop', '##ee', 'express', 'di', 'da', '##era', '##h', 'ja', '##bo', '##de', '##ta', '##bek', 'mel', '##ak', '##uka', '##n', 'mo', '##go', '##k', 'ke', '##r', '##ja', '.', 'mere', '##ka', 'pro', '##tes', 'karen', '##a', 'up', '##ah', '##nya', 'di', '##tur', '##unk', '##an', 'dar', '##i', '5', '.', '000', '/', 'pak', '##et', ',', '3', '.', '500', '/', 'pak', '##et', ',', '2', '.', '500', '/', 'pak', '##et', ',', '&', 'amp', ';', 'pad', '##a', 'aw', '##al', 'april', 'men', '##jad', '##i', '1', '.', '500', '/', 'pak', '##et', '.', 'mere', '##ka', 'tak', 'da', '##pa', '##t', 'up', '##ah', 'minimum', '&', 'amp', ';', 'jam', '##ina', '##n', 'so', '##sia', '##l', '.', '#', 'shop', '##eet', '##inda', '##sk', '##uri', '##r', '.', 'just', 'scheduled', 'my', 'appointment', 'to', 'get', 'the', 'vaccine', '!', '[UNK]', 'i', \"'\", 'm', 'a', 'little', 'nervous', 'because', 'these', 'are', 'the', 'only', 'nurses', 'i', 'trust', '[', '[UNK]', ']', 'so', 'disappointed', '[UNK]', '|', 'i', '##g', 'co', '##vid', 'ma', '##kin', 'mere', '##sa', '##h', '##kan', 'he', 'a', 'chef', 'all', 'godzilla', '##s', 'are', 'beautiful', '.', '\"', 'get', 'me', 'another', 'plate', 'but', 'say', 'its', 'for', 'you', '\"', 'this', 'is', 'why', 'aliens', 'don', \"'\", 't', 'visit', 'us', ':', '(', '(', 'ser', '##ing', 'ter', '##jad', '##i', 'ak', '##u', 'pas', 'di', 'jalan', 'pu', '##lang', 'tia', '##p', 'ab', '##is', 'ke', '##tem', '##u', 'kam', '##u', ':', 'ib', '##u', 'koch', '##eng', 'ba', '##wa', 'ana', '##k', '##nya', 'send', '##iri', 'lang', '##sun', '##g', 'ke', 'rs', 'zoo', 'ka', '##sian', 'tap', '##i', 'gem', '##ey', '[UNK]', 'ak', '##u', 'mint', '##ak', 'to', '##long', 'kali', 'sam', '##a', 'ke', '##len', ':', 'j', '##gn', 'la', 'ba', '##ca', 'bu', '##ku', 'baja', '##kan', '.', 'se', '##di', '##h', 'kali', 'lo', '##h', 'kam', '##i', '.', 'royal', '##ti', 'cum', '##a', '10', '##an', '%', 'ny', '##a', 'dar', '##i', 'ha', '##rga', 'bu', '##ku', '.', 'ke', '##len', 'bel', '##i', 'bu', '##ku', '80', '##rb', ',', 'y', '##g', 'mas', '##uk', 're', '##ken', '##ing', '##ku', '6', '.', '800', 'per', '##ak', 'st', '##l', '##h', 'pot', '##ong', 'pa', '##jak', '.', 'se', '##lam', '##a', 'prose', '##s', 'nu', '##lis', ',', 'ga', '##k', 'ada', 'ga', '##ji', 'kam', '##i', 'dr', 'pen', '##er', '##bit', ',', 'nun', '##gg', '##u', 'ke', '##len', 'bel', '##i', 'br', 'ada', 'du', '##it', '.', '.', 'ga', '##k', 'se', '##mu', '##a', 'idol', 'coco', '##k', '/', 'ma', '##mp', '##u', 'bu', '##at', 'solo', ',', 'si', '##apa', 'tau', 'mere', '##ka', 'peng', '##en', '##nya', 'se', '##mara', '##ng', 'ha', '##gr', '##id', 'and', 'his', 'magical', 'creatures', '[UNK]', 'ada', 'yang', 'peng', '##has', '##ila', '##n', 'be', '##sar', ',', 'tap', '##i', 'un', '##tu', '##k', 'menu', '##tu', '##pi', 'hut', '##ang', 'or', '##ang', 'tu', '##a', '.', 'ada', 'yang', 'ja', '##bat', '##ann', '##ya', 'bag', '##us', ',', 'tap', '##i', 'jar', '##ang', 'pu', '##lang', 'ke', 'rum', '##ah', '.', 'ada', 'yang', 'de', '##kat', 'deng', '##an', 'ke', '##lu', '##ar', '##ga', ',', 'tap', '##i', 'han', '##ya', 'cu', '##ku', '##p', 'un', '##tu', '##k', 'hid', '##up', 'se', '##hari', '-', 'hari', '.', 'jalan', '##nya', 'sam', '##a', 'ter', '##jal', '##nya', ',', 'yang', 'bed', '##a', 'cum', '##a', 'bat', '##un', '##ya', '[UNK]', '.', 'pen', '##ye', '##ba', '##bn', '##ya', 'tu', '##h', 'gin', '##i', '.', '.', '.', 'she', 'always', 'understands', 'the', 'assignment', '.', 'ti', '##kt', '##ok', 'gary', 'barlow', 'bi', '##kin', 'ter', '##inga', '##t', 'za', '##man', 'mtv', '.', 'ala', '##san', '##g', 'cafe', 'coco', '##k', 'bu', '##at', 'non', '##g', '##ki', 'ter', '##us', 'kala', '##u', 'di', '##tan', '##ya', 'ma', '##un', '##ya', 'dim', '##ana', ',', 'jaw', '##aba', '##nn', '##ya', '“', 'ter', '##ser', '##ah', '”', '.', 'men', '##ding', 'di', '##ba', '##wa', 'ke', '##sin', '##i', 'sue', '##r', 'de', '##h', 'w', '##k', '##wk', 'lok', '##asi', ':', 'co', '##ban', 'sand', '##ang', ',', 'pu', '##jon', ',', 'mala', '##ng', '.', 'un', '##tu', '##k', 'ha', '##rga', 'ter', '##sed', '##ia', 'f', '##oto', 'di', '##ba', '##wa', '##hn', '##ya', 'e', '##bie', '##t', 'g', '.', 'ad', '##e', 'sa', '##at', 'ter', '##jad', '##i', 'ben', '##cana', 'alam', 'jam', '##rud', 'set', '##ela', '##h', 'da', '##pet', 'royal', '##ti', 'dar', '##i', 'la', '##gun', '##ya', 'y', '##g', 'dip', '##uter', 'tia', '##p', 'ada', 'or', '##ang', 'ul', '##ta', '##h', ':', 'her', '##an', 'ken', '##apa', 'ban', '##ya', '##k', 'bang', '##et', 'yang', 'ga', 'set', '##uj', '##u', 'so', '##al', 'hal', 'in', '##i', '?', 'pad', '##aha', '##l', 'in', '##i', 'pr', '##ak', '##tek', 'yang', 'lu', '##m', '##rah', 'dan', 'sud', '##ah', 'se', '##har', '##us', '##nya', 'karen', '##a', 'dar', '##i', 'du', '##lu', 'mu', '##sis', '##i', 'serb', '##a', 'ke', '##sul', '##itan', 'so', '##al', 'royal', '##ti', '.', '\"', 'ya', 'kan', 'ud', '##ah', 'kit', '##a', 'apr', '##es', '##ias', '##i', 'ka', '##rya', '##nya', ',', 'mas', '##a', 'di', '##kit', '##2', 'so', '##al', 'ua', '##ng', '\"', 'apr', '##es', '##ias', '##i', 'ga', '##bis', '##a', 'bu', '##at', 'ma', '##kan', 'sam', '##a', 'bay', '##ar', 'list', '##rik', 'so', '##pan', '##ka', '##h', 'beg', '##it', '##u', 'menu', '##n', '##ju', '##k', 'baha', '##gia', '?', '\"', 'ser', '##u', 'hid', '##up', '##nya', '\"', 'i', '##ya', 'yang', 'di', 'tun', '##ju', '##kin', 'kan', 'ser', '##u', '-', 'ser', '##un', '##ya', 'aj', '##a', 'be', '##b', '.', 'just', 'a', 'dude', 'in', 'his', 'kitchen', 'watching', 'sh', '##rek', '2', 'on', 'his', 'fridge', 'lad', '##ang', 'ama', '##l', 'sale', '##h', 'lama', '##2', 'ja', '##di', 'se', '##ked', '##ar', 'sugar', 'coating', 'words', '.', 'al', '##m', 'bo', '##ka', '##p', 'stroke', 'lump', '##uh', 'di', 'rum', '##ah', ',', 'g', '##w', '&', 'amp', ';', 'ny', '##oka', '##p', 'ur', '##us', 'tan', '##pa', 'per', '##awa', '##t', '.', 'bed', '##any', '##a', 'mer', '##awa', '##t', 'lan', '##sia', 'sa', '##kit', '.', 'ka', '##lo', 'bay', '##i', 'asa', '##l', 'gan', '##ti', 'pam', '##pers', ',', 'di', '##kas', '##ih', 'su', '##su', 'ya', 'die', '##m', '.', 'bobo', '##t', 'tub', '##uh', '##nya', 'mas', '##ih', 'ring', '##an', '.', '.', 'protective', 'boyfriend', '.', 'there', 'can', 'only', 'be', 'one', 'dog', '##e', 'in', 'this', 'house', '.', 'says', 'a', 'lot', 'me', ':', '\"', 'i', 'promise', 'i', 'won', \"'\", 't', 'be', 'dramatic', '.', '\"', 'also', 'me', ':', 'date', '##ng', 'ke', 'salon', 'ma', '##u', 'treatment', 'eh', 'mala', '##h', 'did', '##ie', '##min', 'sam', '##a', 'mba', '##k', '##nya', ',', 'ter', '##nya', '##ta', 'gu', '##a', 'di', '##kas', '##ih', 'silent', 'treatment', '.', '1', '.', 'g', '##w', 'bu', '##kan', 'investment', 'manager', '/', 'financial', 'planner', '.', 'tap', '##i', 'menu', '##rut', 'peng', '##ala', '##man', 'g', '##w', ',', 'apart', '##eme', '##n', 'it', '##u', 'bent', '##uk', 'investment', 'y', '##g', 'je', '##le', '##k', 'b', '##gt', '.', 'in', '##i', 'based', 'on', '2', 'apart', '##eme', '##n', 'y', '##g', 'g', '##w', 'p', '##ny', 'di', 'ja', '##ks', '##el', 'and', 'ja', '##k', '##pus', '.', 'in', '##i', 'ala', '##san', '##nya', ':', '.', 'happy', 'birthday', 'to', 'me', 'i', 'wanna', 'do', 'more', 'of', 'these', 'tea', '##cup', 'painting', 'studies', 'that', 'smile', '!', '[UNK]', '#', 'ju', '##kin', '##media', 'fascinating', 'loft', 'house', '#', 'f', '##j', '##house', '##re', '##view', 'bi', '##rb', 'la', '##tte', 'art', '[UNK]', 'by', '(', 'kun', '##it', '##9', '##2', '|', 'i', '##g', ')', '[SEP]']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aS9FCegrJUfw"},"source":["# Set the maximum sequence length. The longest sequence in our training set is 47, but we'll leave room on the end anyway. \n","# In the original paper, the authors used a length of 512.\n","MAX_LEN = 512"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A1rjQS3qJUie"},"source":["input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9nmT6G5oJUlS"},"source":["import os\n","os.environ['KERAS_BACKEND'] = 'tensorflow'\n","from keras.preprocessing.sequence import pad_sequences"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jiIXTvnyJUn7"},"source":["# Pad our input tokens\n","input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nlwHYl7YJbLO"},"source":["# Create attention masks\n","attention_masks = []\n","\n","# Create a mask of 1s for each token followed by 0s for padding\n","for seq in input_ids:\n","    seq_mask = [float(i>0) for i in seq]\n","    attention_masks.append(seq_mask)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"loenLEb3JbOe"},"source":["# Use train_test_split to split our data into train and validation sets for training\n","train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n","                                                            random_state=2020, test_size=0.01)\n","train_masks, validation_masks, _, _ = train_test_split(attention_masks, input_ids,\n","                                             random_state=2020, test_size=0.01)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"h6muAlDeiac7"},"source":["# BERT"]},{"cell_type":"code","metadata":{"id":"UJDljt39iddQ"},"source":["# Convert all of our data into torch tensors, the required datatype for our model\n","\n","train_inputs = torch.tensor(train_inputs)\n","validation_inputs = torch.tensor(validation_inputs)\n","train_labels = torch.tensor(train_labels)\n","validation_labels = torch.tensor(validation_labels)\n","train_masks = torch.tensor(train_masks)\n","validation_masks = torch.tensor(validation_masks)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CgmJ-E_VigTt"},"source":["# Select a batch size for training. For fine-tuning BERT on a specific task, the authors recommend a batch size of 16 or 32\n","batch_size = 8\n","\n","# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n","# with an iterator the entire dataset does not need to be loaded into memory\n","\n","train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n","validation_sampler = SequentialSampler(validation_data)\n","validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["d7eae61dd9f14fbd8e39fda7cab4789a","4bacd2b6e2cc41669e467db2c602923a","90b7fbbbc1ec493f9047c9fefa15967d","eedca87254e7467ba25c7e40fe0fc937","de04b2e7d2a6482cba071549562c163d","8d33917f76874e309d742e770a1f1d42","d5b98fe261624c07b6931d539fe9ce48","23370a5038594115bbe884f43f5908cb","bd1285f3bf404c3583e36a0531a1b31f","5511c9002a7f46b198ef99f94076ae57","a9a733a935f34c16ad6c4a6ffaf13186","f131849b13234badbfcc0db6b059e867","98bf3f867d234a18b06a4826d2bed4c5","4eadc0c7dba14659b05e8867c532d684","54afe0258abc49a1ac79c1e7f2b03ef8","fec95d1f178a4feb8870f027dd4600e8"]},"id":"DDEh2ukbMZmI","executionInfo":{"elapsed":16461,"status":"ok","timestamp":1621582531320,"user":{"displayName":"Partha Kadambi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjE3P9W2kYe0-W6DurXX4DIH5pqdXbrfJR4YU_cxQ=s64","userId":"11913997928897283481"},"user_tz":300},"outputId":"517fe686-9300-4852-a53f-2ff6c3f1774b"},"source":["model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n","model.cuda()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d7eae61dd9f14fbd8e39fda7cab4789a","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=570.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bd1285f3bf404c3583e36a0531a1b31f","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"code","metadata":{"id":"mfwPyoh9ii0x"},"source":["param_optimizer = list(model.named_parameters())\n","no_decay = ['bias', 'gamma', 'beta']\n","optimizer_grouped_parameters = [\n","    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n","     'weight_decay_rate': 0.01},\n","    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n","     'weight_decay_rate': 0.0}\n","]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"likqi1-FimRZ"},"source":["# This variable contains all of the hyperparemeter information our training loop needs\n","optimizer = AdamW(model.parameters(),\n","                  lr = 1e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n","                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n","                )\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JJcXKErgioEE"},"source":["from transformers import get_linear_schedule_with_warmup\n","\n","# Number of training epochs (authors recommend between 2 and 4)\n","epochs = 3\n","\n","# Total number of training steps is number of batches * number of epochs.\n","total_steps = len(train_dataloader) * epochs\n","\n","# Create the learning rate scheduler.\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps = 0, # Default value in run_glue.py\n","                                            num_training_steps = total_steps)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j-fvXJW_ip1k"},"source":["# Function to calculate the accuracy of our predictions vs labels\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LtCJt0A0irEL"},"source":["import time\n","import datetime\n","\n","def format_time(elapsed):\n","    '''\n","    Takes a time in seconds and returns a string hh:mm:ss\n","    '''\n","    # Round to the nearest second.\n","    elapsed_rounded = int(round((elapsed)))\n","    \n","    # Format as hh:mm:ss\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lFW8hfG8Pdv1"},"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nHvyiSNEPoFq","executionInfo":{"elapsed":15,"status":"ok","timestamp":1621582531324,"user":{"displayName":"Partha Kadambi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjE3P9W2kYe0-W6DurXX4DIH5pqdXbrfJR4YU_cxQ=s64","userId":"11913997928897283481"},"user_tz":300},"outputId":"955aefdd-ccd8-4b4e-8eb9-7c6e8e7ba49a"},"source":["device"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{"tags":[]},"execution_count":37}]},{"cell_type":"code","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"wnwi-bj1itbL","outputId":"d88c005c-3d68-43f3-b269-d9c320a1daa5"},"source":["import random\n","torch.cuda.empty_cache()\n","# This training code is based on the `run_glue.py` script here:\n","# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n","\n","# Set the seed value all over the place to make this reproducible.\n","seed_val = 44\n","\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","# Store the average loss after each epoch so we can plot them.\n","loss_values = []\n","\n","# For each epoch...\n","for epoch_i in range(0, epochs):\n","    \n","    # ========================================\n","    #               Training\n","    # ========================================\n","    \n","    # Perform one full pass over the training set.\n","\n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    # Measure how long the training epoch takes.\n","    t0 = time.time()\n","\n","    # Reset the total loss for this epoch.\n","    total_loss = 0\n","\n","    # Put the model into training mode. Don't be mislead--the call to \n","    # `train` just changes the *mode*, it doesn't *perform* the training.\n","    # `dropout` and `batchnorm` layers behave differently during training\n","    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n","    model.train()\n","\n","    # For each batch of training data...\n","    for step, batch in enumerate(train_dataloader):\n","\n","        # Progress update every 40 batches.\n","        if step % 40 == 0 and not step == 0:\n","            # Calculate elapsed time in minutes.\n","            elapsed = format_time(time.time() - t0)\n","            \n","            # Report progress.\n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","\n","        # Unpack this training batch from our dataloader. \n","        #\n","        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n","        # `to` method.\n","        #\n","        # `batch` contains three pytorch tensors:\n","        #   [0]: input ids \n","        #   [1]: attention masks\n","        #   [2]: labels \n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","\n","        # Always clear any previously calculated gradients before performing a\n","        # backward pass. PyTorch doesn't do this automatically because \n","        # accumulating the gradients is \"convenient while training RNNs\". \n","        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n","        model.zero_grad()        \n","\n","        # Perform a forward pass (evaluate the model on this training batch).\n","        # This will return the loss (rather than the model output) because we\n","        # have provided the `labels`.\n","        # The documentation for this `model` function is here: \n","        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n","        b_labels = torch.nn.functional.one_hot(b_labels.to(torch.int64), num_classes=2)\n","\n","        outputs = model(b_input_ids, \n","                    token_type_ids=None, \n","                    attention_mask=b_input_mask, \n","                    labels=b_labels.to(torch.float64))\n","        \n","        # The call to `model` always returns a tuple, so we need to pull the \n","        # loss value out of the tuple.\n","        loss = outputs[0]\n","\n","        # Accumulate the training loss over all of the batches so that we can\n","        # calculate the average loss at the end. `loss` is a Tensor containing a\n","        # single value; the `.item()` function just returns the Python value \n","        # from the tensor.\n","        loss = loss.mean()\n","        total_loss += loss.item()\n","\n","        # Perform a backward pass to calculate the gradients.\n","        loss.backward()\n","\n","        # Clip the norm of the gradients to 1.0.\n","        # This is to help prevent the \"exploding gradients\" problem.\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        # Update parameters and take a step using the computed gradient.\n","        # The optimizer dictates the \"update rule\"--how the parameters are\n","        # modified based on their gradients, the learning rate, etc.\n","        optimizer.step()\n","\n","        # Update the learning rate.\n","        scheduler.step()\n","\n","    # Calculate the average loss over the training data.\n","    avg_train_loss = total_loss / len(train_dataloader)            \n","    \n","    # Store the loss value for plotting the learning curve.\n","    loss_values.append(avg_train_loss)\n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n","        \n","    # ========================================\n","    #               Validation\n","    # ========================================\n","    # After the completion of each training epoch, measure our performance on\n","    # our validation set.\n","\n","    print(\"\")\n","    print(\"Running Validation...\")\n","\n","    t0 = time.time()\n","\n","    # Put the model in evaluation mode--the dropout layers behave differently\n","    # during evaluation.\n","    model.eval()\n","\n","    # Tracking variables \n","    eval_loss, eval_accuracy = 0, 0\n","    nb_eval_steps, nb_eval_examples = 0, 0\n","\n","    # Evaluate data for one epoch\n","    for batch in validation_dataloader:\n","        \n","        # Add batch to GPU\n","        batch = tuple(t.to(device) for t in batch)\n","        \n","        # Unpack the inputs from our dataloader\n","        b_input_ids, b_input_mask, b_labels = batch\n","        \n","        # Telling the model not to compute or store gradients, saving memory and\n","        # speeding up validation\n","        with torch.no_grad():        \n","\n","            # Forward pass, calculate logit predictions.\n","            # This will return the logits rather than the loss because we have\n","            # not provided labels.\n","            # token_type_ids is the same as the \"segment ids\", which \n","            # differentiates sentence 1 and 2 in 2-sentence tasks.\n","            # The documentation for this `model` function is here: \n","            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n","            outputs = model(b_input_ids, \n","                            token_type_ids=None, \n","                            attention_mask=b_input_mask)\n","        \n","        # Get the \"logits\" output by the model. The \"logits\" are the output\n","        # values prior to applying an activation function like the softmax.\n","        logits = outputs[0]\n","\n","        # Move logits and labels to CPU\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","        \n","        # Calculate the accuracy for this batch of test sentences.\n","        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n","        \n","        # Accumulate the total accuracy.\n","        eval_accuracy += tmp_eval_accuracy\n","\n","        # Track the number of batches\n","        nb_eval_steps += 1\n","\n","    # Report the final accuracy for this validation run.\n","    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n","    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n","\n","print(\"\")\n","print(\"Training complete!\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","======== Epoch 1 / 3 ========\n","Training...\n","  Batch    40  of  4,066.    Elapsed: 0:00:18.\n","  Batch    80  of  4,066.    Elapsed: 0:00:36.\n","  Batch   120  of  4,066.    Elapsed: 0:00:54.\n","  Batch   160  of  4,066.    Elapsed: 0:01:12.\n","  Batch   200  of  4,066.    Elapsed: 0:01:30.\n","  Batch   240  of  4,066.    Elapsed: 0:01:48.\n","  Batch   280  of  4,066.    Elapsed: 0:02:06.\n","  Batch   320  of  4,066.    Elapsed: 0:02:24.\n","  Batch   360  of  4,066.    Elapsed: 0:02:42.\n","  Batch   400  of  4,066.    Elapsed: 0:03:00.\n","  Batch   440  of  4,066.    Elapsed: 0:03:18.\n","  Batch   480  of  4,066.    Elapsed: 0:03:36.\n","  Batch   520  of  4,066.    Elapsed: 0:03:54.\n","  Batch   560  of  4,066.    Elapsed: 0:04:12.\n","  Batch   600  of  4,066.    Elapsed: 0:04:30.\n","  Batch   640  of  4,066.    Elapsed: 0:04:48.\n","  Batch   680  of  4,066.    Elapsed: 0:05:06.\n","  Batch   720  of  4,066.    Elapsed: 0:05:24.\n","  Batch   760  of  4,066.    Elapsed: 0:05:42.\n","  Batch   800  of  4,066.    Elapsed: 0:06:00.\n","  Batch   840  of  4,066.    Elapsed: 0:06:18.\n","  Batch   880  of  4,066.    Elapsed: 0:06:36.\n","  Batch   920  of  4,066.    Elapsed: 0:06:54.\n","  Batch   960  of  4,066.    Elapsed: 0:07:12.\n","  Batch 1,000  of  4,066.    Elapsed: 0:07:30.\n","  Batch 1,040  of  4,066.    Elapsed: 0:07:48.\n","  Batch 1,080  of  4,066.    Elapsed: 0:08:06.\n","  Batch 1,120  of  4,066.    Elapsed: 0:08:24.\n","  Batch 1,160  of  4,066.    Elapsed: 0:08:42.\n","  Batch 1,200  of  4,066.    Elapsed: 0:09:00.\n","  Batch 1,240  of  4,066.    Elapsed: 0:09:18.\n","  Batch 1,280  of  4,066.    Elapsed: 0:09:36.\n","  Batch 1,320  of  4,066.    Elapsed: 0:09:54.\n","  Batch 1,360  of  4,066.    Elapsed: 0:10:12.\n","  Batch 1,400  of  4,066.    Elapsed: 0:10:30.\n","  Batch 1,440  of  4,066.    Elapsed: 0:10:48.\n","  Batch 1,480  of  4,066.    Elapsed: 0:11:06.\n","  Batch 1,520  of  4,066.    Elapsed: 0:11:24.\n","  Batch 1,560  of  4,066.    Elapsed: 0:11:42.\n","  Batch 1,600  of  4,066.    Elapsed: 0:12:00.\n","  Batch 1,640  of  4,066.    Elapsed: 0:12:18.\n","  Batch 1,680  of  4,066.    Elapsed: 0:12:36.\n","  Batch 1,720  of  4,066.    Elapsed: 0:12:54.\n","  Batch 1,760  of  4,066.    Elapsed: 0:13:12.\n","  Batch 1,800  of  4,066.    Elapsed: 0:13:30.\n","  Batch 1,840  of  4,066.    Elapsed: 0:13:48.\n","  Batch 1,880  of  4,066.    Elapsed: 0:14:06.\n","  Batch 1,920  of  4,066.    Elapsed: 0:14:24.\n","  Batch 1,960  of  4,066.    Elapsed: 0:14:42.\n","  Batch 2,000  of  4,066.    Elapsed: 0:15:00.\n","  Batch 2,040  of  4,066.    Elapsed: 0:15:17.\n","  Batch 2,080  of  4,066.    Elapsed: 0:15:35.\n","  Batch 2,120  of  4,066.    Elapsed: 0:15:53.\n","  Batch 2,160  of  4,066.    Elapsed: 0:16:11.\n","  Batch 2,200  of  4,066.    Elapsed: 0:16:29.\n","  Batch 2,240  of  4,066.    Elapsed: 0:16:47.\n","  Batch 2,280  of  4,066.    Elapsed: 0:17:05.\n","  Batch 2,320  of  4,066.    Elapsed: 0:17:23.\n","  Batch 2,360  of  4,066.    Elapsed: 0:17:41.\n","  Batch 2,400  of  4,066.    Elapsed: 0:17:59.\n","  Batch 2,440  of  4,066.    Elapsed: 0:18:17.\n","  Batch 2,480  of  4,066.    Elapsed: 0:18:35.\n","  Batch 2,520  of  4,066.    Elapsed: 0:18:53.\n","  Batch 2,560  of  4,066.    Elapsed: 0:19:11.\n","  Batch 2,600  of  4,066.    Elapsed: 0:19:29.\n","  Batch 2,640  of  4,066.    Elapsed: 0:19:47.\n","  Batch 2,680  of  4,066.    Elapsed: 0:20:05.\n","  Batch 2,720  of  4,066.    Elapsed: 0:20:23.\n","  Batch 2,760  of  4,066.    Elapsed: 0:20:41.\n","  Batch 2,800  of  4,066.    Elapsed: 0:20:59.\n","  Batch 2,840  of  4,066.    Elapsed: 0:21:17.\n","  Batch 2,880  of  4,066.    Elapsed: 0:21:35.\n","  Batch 2,920  of  4,066.    Elapsed: 0:21:53.\n","  Batch 2,960  of  4,066.    Elapsed: 0:22:11.\n","  Batch 3,000  of  4,066.    Elapsed: 0:22:29.\n","  Batch 3,040  of  4,066.    Elapsed: 0:22:47.\n","  Batch 3,080  of  4,066.    Elapsed: 0:23:05.\n","  Batch 3,120  of  4,066.    Elapsed: 0:23:23.\n","  Batch 3,160  of  4,066.    Elapsed: 0:23:41.\n","  Batch 3,200  of  4,066.    Elapsed: 0:23:59.\n","  Batch 3,240  of  4,066.    Elapsed: 0:24:17.\n","  Batch 3,280  of  4,066.    Elapsed: 0:24:35.\n","  Batch 3,320  of  4,066.    Elapsed: 0:24:53.\n","  Batch 3,360  of  4,066.    Elapsed: 0:25:11.\n","  Batch 3,400  of  4,066.    Elapsed: 0:25:29.\n","  Batch 3,440  of  4,066.    Elapsed: 0:25:47.\n","  Batch 3,480  of  4,066.    Elapsed: 0:26:05.\n","  Batch 3,520  of  4,066.    Elapsed: 0:26:23.\n","  Batch 3,560  of  4,066.    Elapsed: 0:26:41.\n","  Batch 3,600  of  4,066.    Elapsed: 0:26:59.\n","  Batch 3,640  of  4,066.    Elapsed: 0:27:17.\n","  Batch 3,680  of  4,066.    Elapsed: 0:27:35.\n","  Batch 3,720  of  4,066.    Elapsed: 0:27:53.\n","  Batch 3,760  of  4,066.    Elapsed: 0:28:11.\n","  Batch 3,800  of  4,066.    Elapsed: 0:28:29.\n","  Batch 3,840  of  4,066.    Elapsed: 0:28:47.\n","  Batch 3,880  of  4,066.    Elapsed: 0:29:05.\n","  Batch 3,920  of  4,066.    Elapsed: 0:29:23.\n","  Batch 3,960  of  4,066.    Elapsed: 0:29:41.\n","  Batch 4,000  of  4,066.    Elapsed: 0:29:59.\n","  Batch 4,040  of  4,066.    Elapsed: 0:30:17.\n","\n","  Average training loss: 0.62\n","  Training epcoh took: 0:30:29\n","\n","Running Validation...\n","  Accuracy: 0.68\n","  Validation took: 0:00:06\n","\n","======== Epoch 2 / 3 ========\n","Training...\n","  Batch    40  of  4,066.    Elapsed: 0:00:18.\n","  Batch    80  of  4,066.    Elapsed: 0:00:36.\n","  Batch   120  of  4,066.    Elapsed: 0:00:54.\n","  Batch   160  of  4,066.    Elapsed: 0:01:12.\n","  Batch   200  of  4,066.    Elapsed: 0:01:30.\n","  Batch   240  of  4,066.    Elapsed: 0:01:48.\n","  Batch   280  of  4,066.    Elapsed: 0:02:06.\n","  Batch   320  of  4,066.    Elapsed: 0:02:24.\n","  Batch   360  of  4,066.    Elapsed: 0:02:42.\n","  Batch   400  of  4,066.    Elapsed: 0:03:00.\n","  Batch   440  of  4,066.    Elapsed: 0:03:18.\n","  Batch   480  of  4,066.    Elapsed: 0:03:36.\n","  Batch   520  of  4,066.    Elapsed: 0:03:54.\n","  Batch   560  of  4,066.    Elapsed: 0:04:12.\n","  Batch   600  of  4,066.    Elapsed: 0:04:30.\n","  Batch   640  of  4,066.    Elapsed: 0:04:48.\n","  Batch   680  of  4,066.    Elapsed: 0:05:06.\n","  Batch   720  of  4,066.    Elapsed: 0:05:24.\n","  Batch   760  of  4,066.    Elapsed: 0:05:42.\n","  Batch   800  of  4,066.    Elapsed: 0:06:00.\n","  Batch   840  of  4,066.    Elapsed: 0:06:18.\n","  Batch   880  of  4,066.    Elapsed: 0:06:36.\n","  Batch   920  of  4,066.    Elapsed: 0:06:54.\n","  Batch   960  of  4,066.    Elapsed: 0:07:12.\n","  Batch 1,000  of  4,066.    Elapsed: 0:07:30.\n","  Batch 1,040  of  4,066.    Elapsed: 0:07:48.\n","  Batch 1,080  of  4,066.    Elapsed: 0:08:06.\n","  Batch 1,120  of  4,066.    Elapsed: 0:08:24.\n","  Batch 1,160  of  4,066.    Elapsed: 0:08:42.\n","  Batch 1,200  of  4,066.    Elapsed: 0:09:00.\n","  Batch 1,240  of  4,066.    Elapsed: 0:09:18.\n","  Batch 1,280  of  4,066.    Elapsed: 0:09:36.\n","  Batch 1,320  of  4,066.    Elapsed: 0:09:54.\n","  Batch 1,360  of  4,066.    Elapsed: 0:10:12.\n","  Batch 1,400  of  4,066.    Elapsed: 0:10:30.\n","  Batch 1,440  of  4,066.    Elapsed: 0:10:48.\n","  Batch 1,480  of  4,066.    Elapsed: 0:11:06.\n","  Batch 1,520  of  4,066.    Elapsed: 0:11:24.\n","  Batch 1,560  of  4,066.    Elapsed: 0:11:42.\n","  Batch 1,600  of  4,066.    Elapsed: 0:12:00.\n","  Batch 1,640  of  4,066.    Elapsed: 0:12:18.\n","  Batch 1,680  of  4,066.    Elapsed: 0:12:36.\n","  Batch 1,720  of  4,066.    Elapsed: 0:12:54.\n","  Batch 1,760  of  4,066.    Elapsed: 0:13:12.\n","  Batch 1,800  of  4,066.    Elapsed: 0:13:30.\n","  Batch 1,840  of  4,066.    Elapsed: 0:13:48.\n","  Batch 1,880  of  4,066.    Elapsed: 0:14:06.\n","  Batch 1,920  of  4,066.    Elapsed: 0:14:24.\n","  Batch 1,960  of  4,066.    Elapsed: 0:14:42.\n","  Batch 2,000  of  4,066.    Elapsed: 0:15:00.\n","  Batch 2,040  of  4,066.    Elapsed: 0:15:18.\n","  Batch 2,080  of  4,066.    Elapsed: 0:15:36.\n","  Batch 2,120  of  4,066.    Elapsed: 0:15:54.\n","  Batch 2,160  of  4,066.    Elapsed: 0:16:12.\n","  Batch 2,200  of  4,066.    Elapsed: 0:16:30.\n","  Batch 2,240  of  4,066.    Elapsed: 0:16:48.\n","  Batch 2,280  of  4,066.    Elapsed: 0:17:06.\n","  Batch 2,320  of  4,066.    Elapsed: 0:17:24.\n","  Batch 2,360  of  4,066.    Elapsed: 0:17:42.\n","  Batch 2,400  of  4,066.    Elapsed: 0:18:00.\n","  Batch 2,440  of  4,066.    Elapsed: 0:18:18.\n","  Batch 2,480  of  4,066.    Elapsed: 0:18:36.\n","  Batch 2,520  of  4,066.    Elapsed: 0:18:54.\n","  Batch 2,560  of  4,066.    Elapsed: 0:19:12.\n","  Batch 2,600  of  4,066.    Elapsed: 0:19:30.\n","  Batch 2,640  of  4,066.    Elapsed: 0:19:48.\n","  Batch 2,680  of  4,066.    Elapsed: 0:20:06.\n","  Batch 2,720  of  4,066.    Elapsed: 0:20:24.\n","  Batch 2,760  of  4,066.    Elapsed: 0:20:42.\n","  Batch 2,800  of  4,066.    Elapsed: 0:21:00.\n","  Batch 2,840  of  4,066.    Elapsed: 0:21:18.\n","  Batch 2,880  of  4,066.    Elapsed: 0:21:36.\n","  Batch 2,920  of  4,066.    Elapsed: 0:21:54.\n","  Batch 2,960  of  4,066.    Elapsed: 0:22:12.\n","  Batch 3,000  of  4,066.    Elapsed: 0:22:30.\n","  Batch 3,040  of  4,066.    Elapsed: 0:22:48.\n","  Batch 3,080  of  4,066.    Elapsed: 0:23:06.\n","  Batch 3,120  of  4,066.    Elapsed: 0:23:24.\n","  Batch 3,160  of  4,066.    Elapsed: 0:23:42.\n","  Batch 3,200  of  4,066.    Elapsed: 0:24:00.\n","  Batch 3,240  of  4,066.    Elapsed: 0:24:18.\n","  Batch 3,280  of  4,066.    Elapsed: 0:24:36.\n","  Batch 3,320  of  4,066.    Elapsed: 0:24:54.\n","  Batch 3,360  of  4,066.    Elapsed: 0:25:12.\n","  Batch 3,400  of  4,066.    Elapsed: 0:25:30.\n","  Batch 3,440  of  4,066.    Elapsed: 0:25:48.\n","  Batch 3,480  of  4,066.    Elapsed: 0:26:06.\n","  Batch 3,520  of  4,066.    Elapsed: 0:26:24.\n","  Batch 3,560  of  4,066.    Elapsed: 0:26:42.\n","  Batch 3,600  of  4,066.    Elapsed: 0:27:00.\n","  Batch 3,640  of  4,066.    Elapsed: 0:27:18.\n","  Batch 3,680  of  4,066.    Elapsed: 0:27:36.\n","  Batch 3,720  of  4,066.    Elapsed: 0:27:54.\n","  Batch 3,760  of  4,066.    Elapsed: 0:28:12.\n","  Batch 3,800  of  4,066.    Elapsed: 0:28:30.\n","  Batch 3,840  of  4,066.    Elapsed: 0:28:48.\n","  Batch 3,880  of  4,066.    Elapsed: 0:29:06.\n","  Batch 3,920  of  4,066.    Elapsed: 0:29:24.\n","  Batch 3,960  of  4,066.    Elapsed: 0:29:42.\n","  Batch 4,000  of  4,066.    Elapsed: 0:30:00.\n","  Batch 4,040  of  4,066.    Elapsed: 0:30:18.\n","\n","  Average training loss: 0.57\n","  Training epcoh took: 0:30:30\n","\n","Running Validation...\n","  Accuracy: 0.67\n","  Validation took: 0:00:06\n","\n","======== Epoch 3 / 3 ========\n","Training...\n","  Batch    40  of  4,066.    Elapsed: 0:00:18.\n","  Batch    80  of  4,066.    Elapsed: 0:00:36.\n","  Batch   120  of  4,066.    Elapsed: 0:00:54.\n","  Batch   160  of  4,066.    Elapsed: 0:01:12.\n","  Batch   200  of  4,066.    Elapsed: 0:01:30.\n","  Batch   240  of  4,066.    Elapsed: 0:01:48.\n","  Batch   280  of  4,066.    Elapsed: 0:02:06.\n","  Batch   320  of  4,066.    Elapsed: 0:02:24.\n","  Batch   360  of  4,066.    Elapsed: 0:02:42.\n","  Batch   400  of  4,066.    Elapsed: 0:03:00.\n","  Batch   440  of  4,066.    Elapsed: 0:03:18.\n","  Batch   480  of  4,066.    Elapsed: 0:03:36.\n","  Batch   520  of  4,066.    Elapsed: 0:03:54.\n","  Batch   560  of  4,066.    Elapsed: 0:04:12.\n","  Batch   600  of  4,066.    Elapsed: 0:04:30.\n","  Batch   640  of  4,066.    Elapsed: 0:04:48.\n","  Batch   680  of  4,066.    Elapsed: 0:05:06.\n","  Batch   720  of  4,066.    Elapsed: 0:05:24.\n","  Batch   760  of  4,066.    Elapsed: 0:05:42.\n","  Batch   800  of  4,066.    Elapsed: 0:06:00.\n","  Batch   840  of  4,066.    Elapsed: 0:06:18.\n","  Batch   880  of  4,066.    Elapsed: 0:06:36.\n","  Batch   920  of  4,066.    Elapsed: 0:06:54.\n","  Batch   960  of  4,066.    Elapsed: 0:07:12.\n","  Batch 1,000  of  4,066.    Elapsed: 0:07:30.\n","  Batch 1,040  of  4,066.    Elapsed: 0:07:48.\n","  Batch 1,080  of  4,066.    Elapsed: 0:08:06.\n","  Batch 1,120  of  4,066.    Elapsed: 0:08:24.\n","  Batch 1,160  of  4,066.    Elapsed: 0:08:42.\n","  Batch 1,200  of  4,066.    Elapsed: 0:09:00.\n","  Batch 1,240  of  4,066.    Elapsed: 0:09:18.\n","  Batch 1,280  of  4,066.    Elapsed: 0:09:36.\n","  Batch 1,320  of  4,066.    Elapsed: 0:09:54.\n","  Batch 1,360  of  4,066.    Elapsed: 0:10:12.\n","  Batch 1,400  of  4,066.    Elapsed: 0:10:30.\n","  Batch 1,440  of  4,066.    Elapsed: 0:10:48.\n","  Batch 1,480  of  4,066.    Elapsed: 0:11:06.\n","  Batch 1,520  of  4,066.    Elapsed: 0:11:24.\n","  Batch 1,560  of  4,066.    Elapsed: 0:11:42.\n","  Batch 1,600  of  4,066.    Elapsed: 0:12:00.\n","  Batch 1,640  of  4,066.    Elapsed: 0:12:18.\n","  Batch 1,680  of  4,066.    Elapsed: 0:12:36.\n","  Batch 1,720  of  4,066.    Elapsed: 0:12:54.\n","  Batch 1,760  of  4,066.    Elapsed: 0:13:12.\n","  Batch 1,800  of  4,066.    Elapsed: 0:13:30.\n","  Batch 1,840  of  4,066.    Elapsed: 0:13:48.\n","  Batch 1,880  of  4,066.    Elapsed: 0:14:06.\n","  Batch 1,920  of  4,066.    Elapsed: 0:14:24.\n","  Batch 1,960  of  4,066.    Elapsed: 0:14:42.\n","  Batch 2,000  of  4,066.    Elapsed: 0:15:00.\n","  Batch 2,040  of  4,066.    Elapsed: 0:15:18.\n","  Batch 2,080  of  4,066.    Elapsed: 0:15:36.\n","  Batch 2,120  of  4,066.    Elapsed: 0:15:54.\n","  Batch 2,160  of  4,066.    Elapsed: 0:16:12.\n","  Batch 2,200  of  4,066.    Elapsed: 0:16:30.\n","  Batch 2,240  of  4,066.    Elapsed: 0:16:48.\n","  Batch 2,280  of  4,066.    Elapsed: 0:17:06.\n","  Batch 2,320  of  4,066.    Elapsed: 0:17:24.\n","  Batch 2,360  of  4,066.    Elapsed: 0:17:42.\n","  Batch 2,400  of  4,066.    Elapsed: 0:18:00.\n","  Batch 2,440  of  4,066.    Elapsed: 0:18:18.\n","  Batch 2,480  of  4,066.    Elapsed: 0:18:36.\n","  Batch 2,520  of  4,066.    Elapsed: 0:18:54.\n","  Batch 2,560  of  4,066.    Elapsed: 0:19:12.\n","  Batch 2,600  of  4,066.    Elapsed: 0:19:30.\n","  Batch 2,640  of  4,066.    Elapsed: 0:19:48.\n","  Batch 2,680  of  4,066.    Elapsed: 0:20:06.\n","  Batch 2,720  of  4,066.    Elapsed: 0:20:24.\n","  Batch 2,760  of  4,066.    Elapsed: 0:20:42.\n","  Batch 2,800  of  4,066.    Elapsed: 0:21:00.\n","  Batch 2,840  of  4,066.    Elapsed: 0:21:18.\n","  Batch 2,880  of  4,066.    Elapsed: 0:21:36.\n","  Batch 2,920  of  4,066.    Elapsed: 0:21:54.\n","  Batch 2,960  of  4,066.    Elapsed: 0:22:12.\n","  Batch 3,000  of  4,066.    Elapsed: 0:22:30.\n","  Batch 3,040  of  4,066.    Elapsed: 0:22:48.\n","  Batch 3,080  of  4,066.    Elapsed: 0:23:06.\n","  Batch 3,120  of  4,066.    Elapsed: 0:23:24.\n","  Batch 3,160  of  4,066.    Elapsed: 0:23:42.\n","  Batch 3,200  of  4,066.    Elapsed: 0:24:00.\n","  Batch 3,240  of  4,066.    Elapsed: 0:24:18.\n","  Batch 3,280  of  4,066.    Elapsed: 0:24:36.\n","  Batch 3,320  of  4,066.    Elapsed: 0:24:54.\n","  Batch 3,360  of  4,066.    Elapsed: 0:25:12.\n","  Batch 3,400  of  4,066.    Elapsed: 0:25:30.\n","  Batch 3,440  of  4,066.    Elapsed: 0:25:48.\n","  Batch 3,480  of  4,066.    Elapsed: 0:26:06.\n","  Batch 3,520  of  4,066.    Elapsed: 0:26:24.\n","  Batch 3,560  of  4,066.    Elapsed: 0:26:42.\n","  Batch 3,600  of  4,066.    Elapsed: 0:27:00.\n","  Batch 3,640  of  4,066.    Elapsed: 0:27:18.\n","  Batch 3,680  of  4,066.    Elapsed: 0:27:36.\n","  Batch 3,720  of  4,066.    Elapsed: 0:27:54.\n","  Batch 3,760  of  4,066.    Elapsed: 0:28:12.\n","  Batch 3,800  of  4,066.    Elapsed: 0:28:30.\n","  Batch 3,840  of  4,066.    Elapsed: 0:28:48.\n","  Batch 3,880  of  4,066.    Elapsed: 0:29:06.\n","  Batch 3,920  of  4,066.    Elapsed: 0:29:24.\n","  Batch 3,960  of  4,066.    Elapsed: 0:29:42.\n","  Batch 4,000  of  4,066.    Elapsed: 0:30:00.\n","  Batch 4,040  of  4,066.    Elapsed: 0:30:18.\n","\n","  Average training loss: 0.50\n","  Training epcoh took: 0:30:30\n","\n","Running Validation...\n","  Accuracy: 0.67\n","  Validation took: 0:00:06\n","\n","Training complete!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"EZPeyGKYtoCn"},"source":["# Testing"]},{"cell_type":"markdown","metadata":{"id":"EFogz7jeiycc"},"source":["## Helper function for predicting whether label matches the person's prediction, for one person:"]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"_hVud-_XpIOc"},"source":["import statistics\n","\n","def predict_person(text, label, length):\n","  #  print(len(text))\n","    \n","    split_text = text.split()\n","  #  print('split_text: ', len(split_text))\n","    sentences = []\n","    for i in range(0, int(len(split_text)/length)+1):\n","      sentences.append(' '.join(split_text[0 + i*length : (i+1) * length]))\n","  #  print('sentences: ', len(sentences))\n","    labels = [label] * len(sentences)\n","  #  print(len(labels))\n","   # print(len(sentences))\n","    input_ids = []\n","    for sent in sentences:\n","    # `encode` will:\n","    #   (1) Tokenize the sentence.\n","    #   (2) Prepend the `[CLS]` token to the start.\n","    #   (3) Append the `[SEP]` token to the end.\n","    #   (4) Map tokens to their IDs.\n","        encoded_sent = tokenizer.encode(\n","                        sent,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                   )\n","\n","        input_ids.append(encoded_sent)\n","\n","    input_ids = pad_sequences(input_ids, maxlen=MAX_LEN,\n","                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n","\n","    # Create attention masks\n","    attention_masks = []\n","\n","    # Create a mask of 1s for each token followed by 0s for padding\n","    for seq in input_ids:\n","        seq_mask = [float(i>0) for i in seq]\n","        attention_masks.append(seq_mask)\n","\n","    # Convert to tensors.\n","    prediction_inputs = torch.tensor(input_ids)\n","    prediction_masks = torch.tensor(attention_masks)\n","    prediction_labels = torch.tensor(labels)\n","    # Set the batch size.\n","    batch_size = 32\n","\n","    # Create the DataLoader.\n","    prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n","    prediction_sampler = SequentialSampler(prediction_data)\n","    prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\n","\n","  #  print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n","\n","    # Put model in evaluation mode\n","    model.eval()\n","\n","    # Tracking variables\n","    predictions , true_labels = [], []\n","\n","    # Predict\n","    for batch in prediction_dataloader:\n","    # Add batch to GPU\n","        batch = tuple(t.to(device) for t in batch)\n","\n","    # Unpack the inputs from our dataloader\n","        b_input_ids, b_input_mask, b_labels = batch\n","\n","    # Telling the model not to compute or store gradients, saving memory and\n","    # speeding up prediction\n","        with torch.no_grad():\n","           # Forward pass, calculate logit predictions\n","           outputs = model(b_input_ids, token_type_ids=None,\n","                      attention_mask=b_input_mask)\n","\n","        logits = outputs[0]\n","\n","        # Move logits and labels to CPU\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","\n","        # Store predictions and true labels\n","        predictions.append(logits)\n","        true_labels.append(label_ids)\n","\n","    #for i in range(len(true_labels)):\n","\n","    # The predictions for this batch are a 2-column ndarray (one column for \"0\"\n","    # and one column for \"1\"). Pick the label with the highest value and turn this\n","    # in to a list of 0s and 1s.\n","    correct = 0\n","    num = 0\n","\n","    final_predict_list = []\n","\n","    for i in range(len(true_labels)):\n","\n","        pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n","        [final_predict_list.append(i) for i in pred_labels_i]\n","       # if accuracy_score(pred_labels_i, [0] * len(pred_labels_i)) < 0.5 :\n","        #    correct += 1\n","       # num+=1\n","  #  print('list: ', final_predict_list)\n","  #  print(label)\n","    try: \n","       if (statistics.mode(final_predict_list)==label):\n","          return 1\n","       else:\n","          return 0\n","    except:\n","       return random.randint(0,1)\n","    \n","\n","\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"6wgMSCukpIOd"},"source":["## Final predictive accuracy score:"]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"MRCHO9gRhWwe","outputId":"db7186bf-4bf5-4b95-9a74-e7c42f636d19"},"source":["test_df"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>liked_tweets</th>\n","      <th>intuitive</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>I am 30 minutes into home schooling my 6 year...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1/ I'm in the middle of a skincare deep dive ...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Can’t wait to chat with you on my Onlyfans! 💋...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>eu. mas esse não é o papel de qualquer ator? ...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>I BEAT Stage 3 Colon Cancer in the middle of ...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>309</th>\n","      <td>This is the best thing in my day.. LOL! Pee i...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>310</th>\n","      <td>mood removing ram from a computer while it’s ...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>311</th>\n","      <td>Here's some snaps of some of my favorite stre...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>312</th>\n","      <td>Become ungovernable Lizzo is so gorgeous omg ...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>313</th>\n","      <td>nunca levei o git gud tão a sério quanto tô l...</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>314 rows × 2 columns</p>\n","</div>"],"text/plain":["                                          liked_tweets  intuitive\n","0     I am 30 minutes into home schooling my 6 year...        0.0\n","1     1/ I'm in the middle of a skincare deep dive ...        1.0\n","2     Can’t wait to chat with you on my Onlyfans! 💋...        0.0\n","3     eu. mas esse não é o papel de qualquer ator? ...        0.0\n","4     I BEAT Stage 3 Colon Cancer in the middle of ...        1.0\n","..                                                 ...        ...\n","309   This is the best thing in my day.. LOL! Pee i...        0.0\n","310   mood removing ram from a computer while it’s ...        1.0\n","311   Here's some snaps of some of my favorite stre...        1.0\n","312   Become ungovernable Lizzo is so gorgeous omg ...        1.0\n","313   nunca levei o git gud tão a sério quanto tô l...        0.0\n","\n","[314 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":0}]},{"cell_type":"code","metadata":{"id":"SHUoXLp9pIOd"},"source":["correct = 0\n","num = 0\n","for row in tqdm(range(0, len(test_df.index)), \"testing..\"):\n","    \n","    pred_text = test_df.at[row, 'liked_tweets']\n","    \n","    pred_label = test_df.at[row, target_mode]\n","    if pred_label == 0:\n","      #print('Skipped')\n","      continue    \n","    num+=1\n","    pred = predict_person(pred_text, pred_label, 512)\n","   # print(pred)\n","    if pred == 1:\n","        correct+=1\n","\n","print(\"ACC: \", correct/num)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mta45dc2mlRJ","executionInfo":{"elapsed":196,"status":"ok","timestamp":1621567010460,"user":{"displayName":"Partha Kadambi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjE3P9W2kYe0-W6DurXX4DIH5pqdXbrfJR4YU_cxQ=s64","userId":"11913997928897283481"},"user_tz":300},"outputId":"e2799e9c-adc7-4fc6-e5ea-c020361c680b"},"source":["print(\"ACC: \", correct/num)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["ACC:  0.6763005780346821\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OdE6nDKrm80Z","executionInfo":{"elapsed":180,"status":"ok","timestamp":1621567014776,"user":{"displayName":"Partha Kadambi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjE3P9W2kYe0-W6DurXX4DIH5pqdXbrfJR4YU_cxQ=s64","userId":"11913997928897283481"},"user_tz":300},"outputId":"950f179a-95bf-4ef0-9afe-2a9bb381dfcb"},"source":["num"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["173"]},"metadata":{"tags":[]},"execution_count":121}]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"aTxgmJvCpIOe"},"source":["## Saving model to disk"]},{"cell_type":"code","metadata":{"id":"m2-8joASpIOe","outputId":"b3dbcd3a-b91a-4505-dcef-ee1e7bb295a8"},"source":["import os\n","\n","# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n","\n","output_dir = 'BERT_roles'\n","\n","# Create output directory if needed\n","if not os.path.exists(output_dir):\n","    os.makedirs(output_dir)\n","\n","print(\"Saving model to %s\" % output_dir)\n","\n","# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n","# They can then be reloaded using `from_pretrained()`\n","model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n","model_to_save.save_pretrained(output_dir)\n","tokenizer.save_pretrained(output_dir)\n","\n","# Good practice: save your training arguments together with the trained model\n","# torch.save(args, os.path.join(output_dir, 'training_args.bin'))\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Saving model to BERT_roles\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["('BERT_roles/tokenizer_config.json',\n"," 'BERT_roles/special_tokens_map.json',\n"," 'BERT_roles/vocab.txt',\n"," 'BERT_roles/added_tokens.json')"]},"metadata":{"tags":[]},"execution_count":37}]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"xTPRofZwpIOf"},"source":["\n","## Sandbox (the outputs from these code chunks are not up to date and were performed ad hoc)"]},{"cell_type":"code","metadata":{"id":"evRWY1MSpIOf"},"source":["raw_df = raw_df.drop_duplicates()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-FcDihBnpIOf","outputId":"8a6f0243-3be3-44a3-bc83-487d3959746c"},"source":["raw_df\n","raw_set = set(raw_df['liked_by'])\n","print(len(raw_set))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["4186\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IqTg7TmBpIOf"},"source":["train_df, test_df = train_test_split(raw_df, stratify = raw_df['type'], random_state= 1729, test_size= 0.12)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0Ulk5Z5-pIOg","outputId":"d7dfbe61-b26d-4deb-d2dc-b73d7aada6e1"},"source":["train_set = set(edf['liked_by'])\n","print(len(train_set))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["3680\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tukcs8j2pIOg","outputId":"def51af5-b4e8-4b39-ba6b-361733b75c63"},"source":["test_set = set(test_df['liked_by'])\n","print(len(test_set))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["503\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ccW1-hPXpIOg","outputId":"b6c40810-84d2-4db0-e60a-d039e958d51a"},"source":["i = 0\n","for val in set(test_df['liked_by']):\n","    if val in train_set:\n","        i+=1\n","        print(val)\n","        print('dude wtf')\n","print(i)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2prZlPzCpIOg","outputId":"06900290-c14e-4fde-e16e-fe08af24a488"},"source":["df[df['liked_by']==856944637575090176]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>liked_by</th>\n","      <th>text</th>\n","      <th>type</th>\n","      <th>extravert</th>\n","      <th>intuitive</th>\n","      <th>thinking</th>\n","      <th>judging</th>\n","      <th>NT</th>\n","      <th>SF</th>\n","      <th>NF</th>\n","      <th>ST</th>\n","      <th>NJ</th>\n","      <th>NP</th>\n","      <th>SJ</th>\n","      <th>SP</th>\n","      <th>tokenized_texts</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1827</th>\n","      <td>856944637575090176</td>\n","      <td>doing this for Rue. I couldn’t type all I’m fe...</td>\n","      <td>ENTJ</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>['[CLS]', 'doing', 'this', 'for', 'rue', '.', ...</td>\n","    </tr>\n","    <tr>\n","      <th>3396</th>\n","      <td>856944637575090176</td>\n","      <td>a medal of freedom tbh... your move Biden@sar...</td>\n","      <td>ENTJ</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>['[CLS]', 'a', 'medal', 'of', 'freedom', 'tb',...</td>\n","    </tr>\n","    <tr>\n","      <th>4854</th>\n","      <td>856944637575090176</td>\n","      <td>rl who raises the dead for $$$. Out 8.24.2021!...</td>\n","      <td>ENTJ</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>['[CLS]', 'r', '##l', 'who', 'raises', 'the', ...</td>\n","    </tr>\n","    <tr>\n","      <th>13563</th>\n","      <td>856944637575090176</td>\n","      <td>trying to tell someone I didn’t believe in me...</td>\n","      <td>ENTJ</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>['[CLS]', 'trying', 'to', 'tell', 'someone', '...</td>\n","    </tr>\n","    <tr>\n","      <th>18242</th>\n","      <td>856944637575090176</td>\n","      <td>is FIVE DAYS AWAY!!! Since it’s almost the new...</td>\n","      <td>ENTJ</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>['[CLS]', 'is', 'five', 'days', 'away', '!', '...</td>\n","    </tr>\n","    <tr>\n","      <th>19429</th>\n","      <td>856944637575090176</td>\n","      <td>ir wine with food\\n\\nA dark god with fine tast...</td>\n","      <td>ENTJ</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>['[CLS]', 'ir', 'wine', 'with', 'food', 'a', '...</td>\n","    </tr>\n","    <tr>\n","      <th>32099</th>\n","      <td>856944637575090176</td>\n","      <td>solid Norse number, I commissioned 9 character...</td>\n","      <td>ENTJ</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>['[CLS]', 'solid', 'norse', 'number', ',', 'i'...</td>\n","    </tr>\n","    <tr>\n","      <th>32897</th>\n","      <td>856944637575090176</td>\n","      <td>\\n\\nwhat the hell did they expect me to eat th...</td>\n","      <td>ENTJ</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>['[CLS]', 'what', 'the', 'hell', 'did', 'they'...</td>\n","    </tr>\n","    <tr>\n","      <th>33639</th>\n","      <td>856944637575090176</td>\n","      <td>s part out during revisions, what if the chapt...</td>\n","      <td>ENTJ</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>['[CLS]', 's', 'part', 'out', 'during', 'revis...</td>\n","    </tr>\n","    <tr>\n","      <th>34696</th>\n","      <td>856944637575090176</td>\n","      <td>/t.co/ArcG41MLtG@sarahcatstreet b4$ !!Just got...</td>\n","      <td>ENTJ</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>['[CLS]', '/', 't', '.', 'co', '/', 'arc', '##...</td>\n","    </tr>\n","    <tr>\n","      <th>36578</th>\n","      <td>856944637575090176</td>\n","      <td>the same notes over and over, so here is Quer...</td>\n","      <td>ENTJ</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>['[CLS]', 'the', 'same', 'notes', 'over', 'and...</td>\n","    </tr>\n","    <tr>\n","      <th>44558</th>\n","      <td>856944637575090176</td>\n","      <td>o icon-ify me, and i'm obsessed with the resul...</td>\n","      <td>ENTJ</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>['[CLS]', 'o', 'icon', '-', 'if', '##y', 'me',...</td>\n","    </tr>\n","    <tr>\n","      <th>46841</th>\n","      <td>856944637575090176</td>\n","      <td>ised for a yearwhen you’ve been away from your...</td>\n","      <td>ENTJ</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>['[CLS]', 'is', '##ed', 'for', 'a', 'year', '#...</td>\n","    </tr>\n","    <tr>\n","      <th>51946</th>\n","      <td>856944637575090176</td>\n","      <td>to my twenties: you brought me all the best an...</td>\n","      <td>ENTJ</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>['[CLS]', 'to', 'my', 'twenties', ':', 'you', ...</td>\n","    </tr>\n","    <tr>\n","      <th>56783</th>\n","      <td>856944637575090176</td>\n","      <td>were right, it CAN kill a human being in unde...</td>\n","      <td>ENTJ</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>['[CLS]', 'were', 'right', ',', 'it', 'can', '...</td>\n","    </tr>\n","    <tr>\n","      <th>61720</th>\n","      <td>856944637575090176</td>\n","      <td>only to teach you what absolutely doesn’t work...</td>\n","      <td>ENTJ</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>['[CLS]', 'only', 'to', 'teach', 'you', 'what'...</td>\n","    </tr>\n","    <tr>\n","      <th>63004</th>\n","      <td>856944637575090176</td>\n","      <td>jace herondale.\\n\\nthat’s it. that’s the twee...</td>\n","      <td>ENTJ</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>['[CLS]', 'jace', 'heron', '##dale', '.', 'tha...</td>\n","    </tr>\n","    <tr>\n","      <th>63251</th>\n","      <td>856944637575090176</td>\n","      <td>quel to #lotr. Set in the era of Aragorn's son...</td>\n","      <td>ENTJ</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>['[CLS]', 'que', '##l', 'to', '#', 'lot', '##r...</td>\n","    </tr>\n","    <tr>\n","      <th>64260</th>\n","      <td>856944637575090176</td>\n","      <td>will show and six of you will be dead.” https:...</td>\n","      <td>ENTJ</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>['[CLS]', 'will', 'show', 'and', 'six', 'of', ...</td>\n","    </tr>\n","    <tr>\n","      <th>69200</th>\n","      <td>856944637575090176</td>\n","      <td>utine. https://t.co/ZPGjLGmdhS@sarahcatstreet ...</td>\n","      <td>ENTJ</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>['[CLS]', 'ut', '##ine', '.', 'https', ':', '/...</td>\n","    </tr>\n","    <tr>\n","      <th>72638</th>\n","      <td>856944637575090176</td>\n","      <td>s the same name as one of my children #ammteas...</td>\n","      <td>ENTJ</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>['[CLS]', 's', 'the', 'same', 'name', 'as', 'o...</td>\n","    </tr>\n","    <tr>\n","      <th>73872</th>\n","      <td>856944637575090176</td>\n","      <td>o.  \\n\\n(And, hey, that's longer than my last ...</td>\n","      <td>ENTJ</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>['[CLS]', 'o', '.', '(', 'and', ',', 'hey', ',...</td>\n","    </tr>\n","    <tr>\n","      <th>75666</th>\n","      <td>856944637575090176</td>\n","      <td>ink you all probably know this already but jus...</td>\n","      <td>ENTJ</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>['[CLS]', 'ink', 'you', 'all', 'probably', 'kn...</td>\n","    </tr>\n","    <tr>\n","      <th>77253</th>\n","      <td>856944637575090176</td>\n","      <td>. https://t.co/XExDGWc32xnever stan real peopl...</td>\n","      <td>ENTJ</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>['[CLS]', '.', 'https', ':', '/', '/', 't', '....</td>\n","    </tr>\n","    <tr>\n","      <th>77453</th>\n","      <td>856944637575090176</td>\n","      <td>to 2016 tumblr ever againWant blue check unde...</td>\n","      <td>ENTJ</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>['[CLS]', 'to', '2016', 'tu', '##mb', '##lr', ...</td>\n","    </tr>\n","    <tr>\n","      <th>79255</th>\n","      <td>856944637575090176</td>\n","      <td>gothsI saw BWB’s ARC for the first time. I ope...</td>\n","      <td>ENTJ</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>['[CLS]', 'goth', '##si', 'saw', 'b', '##w', '...</td>\n","    </tr>\n","    <tr>\n","      <th>84801</th>\n","      <td>856944637575090176</td>\n","      <td>.... no further notes on this for now just pro...</td>\n","      <td>ENTJ</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>['[CLS]', '.', '.', '.', '.', 'no', 'further',...</td>\n","    </tr>\n","    <tr>\n","      <th>90797</th>\n","      <td>856944637575090176</td>\n","      <td>’s puppy had to have emergency surgery and the...</td>\n","      <td>ENTJ</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>['[CLS]', '’', 's', 'puppy', 'had', 'to', 'hav...</td>\n","    </tr>\n","    <tr>\n","      <th>91206</th>\n","      <td>856944637575090176</td>\n","      <td>r holy shitmight do a newsletter this week wit...</td>\n","      <td>ENTJ</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>['[CLS]', 'r', 'holy', 'shit', '##mi', '##ght'...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                 liked_by                                               text  \\\n","1827   856944637575090176  doing this for Rue. I couldn’t type all I’m fe...   \n","3396   856944637575090176   a medal of freedom tbh... your move Biden@sar...   \n","4854   856944637575090176  rl who raises the dead for $$$. Out 8.24.2021!...   \n","13563  856944637575090176   trying to tell someone I didn’t believe in me...   \n","18242  856944637575090176  is FIVE DAYS AWAY!!! Since it’s almost the new...   \n","19429  856944637575090176  ir wine with food\\n\\nA dark god with fine tast...   \n","32099  856944637575090176  solid Norse number, I commissioned 9 character...   \n","32897  856944637575090176  \\n\\nwhat the hell did they expect me to eat th...   \n","33639  856944637575090176  s part out during revisions, what if the chapt...   \n","34696  856944637575090176  /t.co/ArcG41MLtG@sarahcatstreet b4$ !!Just got...   \n","36578  856944637575090176   the same notes over and over, so here is Quer...   \n","44558  856944637575090176  o icon-ify me, and i'm obsessed with the resul...   \n","46841  856944637575090176  ised for a yearwhen you’ve been away from your...   \n","51946  856944637575090176  to my twenties: you brought me all the best an...   \n","56783  856944637575090176   were right, it CAN kill a human being in unde...   \n","61720  856944637575090176  only to teach you what absolutely doesn’t work...   \n","63004  856944637575090176   jace herondale.\\n\\nthat’s it. that’s the twee...   \n","63251  856944637575090176  quel to #lotr. Set in the era of Aragorn's son...   \n","64260  856944637575090176  will show and six of you will be dead.” https:...   \n","69200  856944637575090176  utine. https://t.co/ZPGjLGmdhS@sarahcatstreet ...   \n","72638  856944637575090176  s the same name as one of my children #ammteas...   \n","73872  856944637575090176  o.  \\n\\n(And, hey, that's longer than my last ...   \n","75666  856944637575090176  ink you all probably know this already but jus...   \n","77253  856944637575090176  . https://t.co/XExDGWc32xnever stan real peopl...   \n","77453  856944637575090176   to 2016 tumblr ever againWant blue check unde...   \n","79255  856944637575090176  gothsI saw BWB’s ARC for the first time. I ope...   \n","84801  856944637575090176  .... no further notes on this for now just pro...   \n","90797  856944637575090176  ’s puppy had to have emergency surgery and the...   \n","91206  856944637575090176  r holy shitmight do a newsletter this week wit...   \n","\n","       type  extravert  intuitive  thinking  judging  NT  SF  NF  ST  NJ  NP  \\\n","1827   ENTJ          1          1         1        1   1   0   0   0   1   0   \n","3396   ENTJ          1          1         1        1   1   0   0   0   1   0   \n","4854   ENTJ          1          1         1        1   1   0   0   0   1   0   \n","13563  ENTJ          1          1         1        1   1   0   0   0   1   0   \n","18242  ENTJ          1          1         1        1   1   0   0   0   1   0   \n","19429  ENTJ          1          1         1        1   1   0   0   0   1   0   \n","32099  ENTJ          1          1         1        1   1   0   0   0   1   0   \n","32897  ENTJ          1          1         1        1   1   0   0   0   1   0   \n","33639  ENTJ          1          1         1        1   1   0   0   0   1   0   \n","34696  ENTJ          1          1         1        1   1   0   0   0   1   0   \n","36578  ENTJ          1          1         1        1   1   0   0   0   1   0   \n","44558  ENTJ          1          1         1        1   1   0   0   0   1   0   \n","46841  ENTJ          1          1         1        1   1   0   0   0   1   0   \n","51946  ENTJ          1          1         1        1   1   0   0   0   1   0   \n","56783  ENTJ          1          1         1        1   1   0   0   0   1   0   \n","61720  ENTJ          1          1         1        1   1   0   0   0   1   0   \n","63004  ENTJ          1          1         1        1   1   0   0   0   1   0   \n","63251  ENTJ          1          1         1        1   1   0   0   0   1   0   \n","64260  ENTJ          1          1         1        1   1   0   0   0   1   0   \n","69200  ENTJ          1          1         1        1   1   0   0   0   1   0   \n","72638  ENTJ          1          1         1        1   1   0   0   0   1   0   \n","73872  ENTJ          1          1         1        1   1   0   0   0   1   0   \n","75666  ENTJ          1          1         1        1   1   0   0   0   1   0   \n","77253  ENTJ          1          1         1        1   1   0   0   0   1   0   \n","77453  ENTJ          1          1         1        1   1   0   0   0   1   0   \n","79255  ENTJ          1          1         1        1   1   0   0   0   1   0   \n","84801  ENTJ          1          1         1        1   1   0   0   0   1   0   \n","90797  ENTJ          1          1         1        1   1   0   0   0   1   0   \n","91206  ENTJ          1          1         1        1   1   0   0   0   1   0   \n","\n","       SJ  SP                                    tokenized_texts  \n","1827    0   0  ['[CLS]', 'doing', 'this', 'for', 'rue', '.', ...  \n","3396    0   0  ['[CLS]', 'a', 'medal', 'of', 'freedom', 'tb',...  \n","4854    0   0  ['[CLS]', 'r', '##l', 'who', 'raises', 'the', ...  \n","13563   0   0  ['[CLS]', 'trying', 'to', 'tell', 'someone', '...  \n","18242   0   0  ['[CLS]', 'is', 'five', 'days', 'away', '!', '...  \n","19429   0   0  ['[CLS]', 'ir', 'wine', 'with', 'food', 'a', '...  \n","32099   0   0  ['[CLS]', 'solid', 'norse', 'number', ',', 'i'...  \n","32897   0   0  ['[CLS]', 'what', 'the', 'hell', 'did', 'they'...  \n","33639   0   0  ['[CLS]', 's', 'part', 'out', 'during', 'revis...  \n","34696   0   0  ['[CLS]', '/', 't', '.', 'co', '/', 'arc', '##...  \n","36578   0   0  ['[CLS]', 'the', 'same', 'notes', 'over', 'and...  \n","44558   0   0  ['[CLS]', 'o', 'icon', '-', 'if', '##y', 'me',...  \n","46841   0   0  ['[CLS]', 'is', '##ed', 'for', 'a', 'year', '#...  \n","51946   0   0  ['[CLS]', 'to', 'my', 'twenties', ':', 'you', ...  \n","56783   0   0  ['[CLS]', 'were', 'right', ',', 'it', 'can', '...  \n","61720   0   0  ['[CLS]', 'only', 'to', 'teach', 'you', 'what'...  \n","63004   0   0  ['[CLS]', 'jace', 'heron', '##dale', '.', 'tha...  \n","63251   0   0  ['[CLS]', 'que', '##l', 'to', '#', 'lot', '##r...  \n","64260   0   0  ['[CLS]', 'will', 'show', 'and', 'six', 'of', ...  \n","69200   0   0  ['[CLS]', 'ut', '##ine', '.', 'https', ':', '/...  \n","72638   0   0  ['[CLS]', 's', 'the', 'same', 'name', 'as', 'o...  \n","73872   0   0  ['[CLS]', 'o', '.', '(', 'and', ',', 'hey', ',...  \n","75666   0   0  ['[CLS]', 'ink', 'you', 'all', 'probably', 'kn...  \n","77253   0   0  ['[CLS]', '.', 'https', ':', '/', '/', 't', '....  \n","77453   0   0  ['[CLS]', 'to', '2016', 'tu', '##mb', '##lr', ...  \n","79255   0   0  ['[CLS]', 'goth', '##si', 'saw', 'b', '##w', '...  \n","84801   0   0  ['[CLS]', '.', '.', '.', '.', 'no', 'further',...  \n","90797   0   0  ['[CLS]', '’', 's', 'puppy', 'had', 'to', 'hav...  \n","91206   0   0  ['[CLS]', 'r', 'holy', 'shit', '##mi', '##ght'...  "]},"metadata":{"tags":[]},"execution_count":104}]},{"cell_type":"code","metadata":{"id":"Jc825p1FpIOh","outputId":"63ed4437-3b0f-437b-cadf-6ca561f12742"},"source":["testing_df[testing_df['liked_by']==856944637575090176]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>liked_by</th>\n","      <th>text</th>\n","      <th>type</th>\n","      <th>extravert</th>\n","      <th>intuitive</th>\n","      <th>thinking</th>\n","      <th>judging</th>\n","      <th>NT</th>\n","      <th>SF</th>\n","      <th>NF</th>\n","      <th>ST</th>\n","      <th>NJ</th>\n","      <th>NP</th>\n","      <th>SJ</th>\n","      <th>SP</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>3</th>\n","      <td>856944637575090176</td>\n","      <td>me coming into 99+ tiktok notifs wondering wha...</td>\n","      <td>ENTJ</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             liked_by                                               text  \\\n","3  856944637575090176  me coming into 99+ tiktok notifs wondering wha...   \n","\n","   type  extravert  intuitive  thinking  judging  NT  SF  NF  ST  NJ  NP  SJ  \\\n","3  ENTJ          1          1         1        1   1   0   0   0   1   0   0   \n","\n","   SP  \n","3   0  "]},"metadata":{"tags":[]},"execution_count":105}]},{"cell_type":"code","metadata":{"id":"N_G75CjLpIOh","outputId":"ae459227-3fd7-445a-e4b5-f9e55aba63c8"},"source":["predict_person(testing_df.at[45, 'text'], testing_df.at[45, 'thinking'], 256)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0]\n","[1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1]\n","1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PkFEVcBrpIOh","outputId":"86f21ffe-452c-4cff-a1cf-53b609908e3e"},"source":["for row in range(300,340):\n","   print(predict_person(testing_df.at[row, 'text'], testing_df.at[row, 'intuitive'], 256))\n","   print(test_df.at[row, 'intuitive'])\n","   print(\" \")\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1\n","1\n"," \n","1\n","0\n"," \n","1\n","1\n"," \n","1\n","1\n"," \n","1\n","0\n"," \n","1\n","1\n"," \n","1\n","1\n"," \n","1\n","1\n"," \n","0\n","1\n"," \n","1\n","1\n"," \n","1\n","0\n"," \n","1\n","1\n"," \n","1\n","0\n"," \n","1\n","1\n"," \n","1\n","1\n"," \n","1\n","1\n"," \n","1\n","1\n"," \n","1\n","1\n"," \n","0\n","0\n"," \n","0\n","0\n"," \n","1\n","0\n"," \n","1\n","0\n"," \n","1\n","0\n"," \n","1\n","0\n"," \n","1\n","1\n"," \n","0\n","1\n"," \n","0\n","0\n"," \n","1\n","1\n"," \n","1\n","1\n"," \n","1\n","1\n"," \n","1\n","1\n"," \n","1\n","0\n"," \n","1\n","1\n"," \n","1\n","1\n"," \n","0\n","0\n"," \n","0\n","0\n"," \n","1\n","1\n"," \n","1\n","0\n"," \n","1\n","1\n"," \n","1\n","1\n"," \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NUOT-tnCpIOi"},"source":["# Report the number of sentences.\n","print('Number of persons in test set: {:,}\\n'.format(test_df.shape[0]))\n","\n","print('Positive samples: %d of %d (%.2f%%)' % (test_df.judging.sum(), len(test_df.judging), (test_df.judging.sum() / len(test_df.judging) * 100.0)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hIoseqqzt1pc"},"source":["# from sklearn.metrics import matthews_corrcoef\n","#\n","# matthews_set = []\n","#\n","# # Evaluate each test batch using Matthew's correlation coefficient\n","# print('Calculating Matthews Corr. Coef. for each batch...')\n","#\n","# # For each input batch...\n","# for i in range(len(true_labels)):\n","#\n","#     # The predictions for this batch are a 2-column ndarray (one column for \"0\"\n","#     # and one column for \"1\"). Pick the label with the highest value and turn this\n","#     # in to a list of 0s and 1s.\n","#     pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n","#\n","#     # Calculate and store the coef for this batch.\n","#     matthews = matthews_corrcoef(true_labels[i], pred_labels_i)\n","#     matthews_set.append(matthews)\n","#"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_BreKUJ9t25l"},"source":["#matthews_set"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"20s0Poipt6XT"},"source":["# Combine the predictions for each batch into a single list of 0s and 1s.\n","# flat_predictions = [item for sublist in predictions for item in sublist]\n","# flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n","#\n","# # Combine the correct labels for each batch into a single list.\n","# flat_true_labels = [item for sublist in true_labels for item in sublist]\n","#\n","# # Calculate the MCC\n","# mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n","#\n","# print('MCC: %.3f' % mcc)\n","\n","\n","\n"],"execution_count":null,"outputs":[]}]}